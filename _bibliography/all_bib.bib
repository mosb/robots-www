
@article{rajpaul_gaussian_2015,
	title = {A {Gaussian} process framework for modelling stellar activity signals in radial velocity data},
	volume = {452},
	issn = {0035-8711, 1365-2966},
	url = {http://mnras.oxfordjournals.org/content/452/3/2269},
	doi = {10.1093/mnras/stv1428},
	abstract = {To date, the radial velocity (RV) method has been one of the most productive techniques for detecting and confirming extrasolar planetary candidates. Unfortunately, stellar activity can induce RV variations which can drown out or even mimic planetary signals – and it is notoriously difficult to model and thus mitigate the effects of these activity-induced nuisance signals. This is expected to be a major obstacle to using next-generation spectrographs to detect lower mass planets, planets with longer periods, and planets around more active stars. Enter Gaussian processes (GPs) which, we note, have a number of attractive features that make them very well suited to disentangling stellar activity signals from planetary signals. We present here a GP framework we developed to model RV time series jointly with ancillary activity indicators (e.g. bisector velocity spans, line widths, chromospheric activity indices), allowing the activity component of RV time series to be constrained and disentangled from e.g. planetary components. We discuss the mathematical details of our GP framework, and present results illustrating its encouraging performance on both synthetic and real RV data sets, including the publicly available Alpha Centauri B data set.},
	language = {en},
	number = {3},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Rajpaul, Vinesh and Aigrain, Suzanne and Osborne, Michael A. and Reece, Steve and Roberts, Stephen J.},
	month = sep,
	year = {2015},
	keywords = {methods: data analysis, planetary systems, stars: activity, stars: individual: Alpha Centauri B, stars: individual: Gliese 15 A, techniques: radial velocities},
	pages = {2269--2291},
	file = {5543/Rajpaul et al_2015_A Gaussian process framework for modelling stellar activity signals in radial.pdf},
}

@article{hennig_probabilistic_2015,
	title = {Probabilistic {Numerics} and {Uncertainty} in {Computations}},
	volume = {471},
	issn = {1364-5021},
	url = {http://rspa.royalsocietypublishing.org/content/royprsa/471/2179/20150142.full.pdf?ijkey=wr6Ggr6GGGgbJYr&keytype=ref},
	doi = {10.1098/rspa.2015.0142},
	abstract = {We deliver a call to arms for probabilistic numerical methods: algorithms for numerical tasks, including linear algebra, integration, optimization and solving differential equations, that return uncertainties in their calculations. Such uncertainties, arising from the loss of precision induced by numerical calculation with limited time or hardware, are important for much contemporary science and industry. Within applications such as climate science and astrophysics, the need to make decisions on the basis of computations with large and complex data has led to a renewed focus on the management of numerical uncertainty. We describe how several seminal classic numerical methods can be interpreted naturally as probabilistic inference. We then show that the probabilistic view suggests new algorithms that can flexibly be adapted to suit application specifics, while delivering improved empirical performance. We provide concrete illustrations of the benefits of probabilistic numeric algorithms on real scientific problems from astrometry and astronomical imaging, while highlighting open problems with these new algorithms. Finally, we describe how probabilistic numerical methods provide a coherent framework for identifying the uncertainty in calculations performed with a combination of numerical algorithms (e.g. both numerical optimisers and differential equation solvers), potentially allowing the diagnosis (and control) of error sources in computations.},
	number = {2179},
	journal = {Proceedings of the Royal Society A},
	author = {Hennig, Philipp and Osborne, Michael A. and Girolami, Mark A.},
	year = {2015},
	file = {5645/Hennig et al_2015_Probabilistic Numerics and Uncertainty in Computations.pdf},
}

@article{garnett_sequential_2010,
	title = {Sequential {Bayesian} prediction in the presence of changepoints and faults},
	volume = {53},
	doi = {doi:10.1093/comjnl/bxq003},
	abstract = {We introduce a new sequential algorithm for making robust predictions in the presence of changepoints. Unlike previous approaches, which focus on the problem of detecting and locating changepoints, our algorithm focuses on the problem of making predictions even when such changes might be present. We introduce nonstationary covariance functions to be used in Gaussian process prediction that model such changes, and then proceed to demonstrate how to effectively manage the hyperparameters associated with those covariance functions. We further introduce covariance functions to be used in situations where our observation model undergoes changes, as is the case for sensor faults. By using Bayesian quadrature, we can integrate out the hyperparameters, allowing us to calculate the full marginal predictive distribution. Furthermore, if desired, the posterior distribution over putative changepoint locations can be calculated as a natural byproduct of our prediction algorithm.},
	number = {9},
	journal = {The Computer Journal},
	author = {Garnett, Roman and Osborne, Michael A. and Reece, Steven and Rogers, Alex and Roberts, Stephen J.},
	year = {2010},
	pages = {1430},
	file = {5910/Garnett et al_2010_Sequential Bayesian prediction in the presence of changepoints and faults.pdf},
}

@article{luca_photodegradation_2006,
	title = {Photodegradation of methylene blue using crystalline titanosilicate quantum-confined semiconductor},
	volume = {18},
	url = {http://pubs.acs.org/doi/abs/10.1021/cm052839p},
	doi = {10.1021/cm052839p},
	abstract = {Synthetic sitinakite contains in its structure a discrete wire-like sublattice of linked TiO6 octahedra. This sublattice is held apart by silicate tetrahedra forming one-dimensional channels that run down the c axis. The optical properties of this structural arrangement have been studied and compared with other titanosilicate phases, the best known being ETS-10. Thus, sitinakite which has twice the titanate wire diameter of ETS-10 has a band gap of 4.07 eV compared with 3.87 eV. The reduced electron−hole effective mass of the sitinakite quantum-confined system has been calculated through use of the effective mass model and compared with that of other titanosilicate materials. The sitinakite phase has been shown to effectively photodegrade methylene blue (MB) dye at pH 7 using visible light excitation and displays a higher degradation rate than TiO2 (Degussa, P25) under the same experimental conditions. On the contrary, under UV excitation, the photodegradation rate obtained using P25 is much higher than that using sitinakite. Given that the band edge of sitinkaite is significantly blue shifted compared with that of P25, photodegradation of MB using sitinakite is attributed to sensitization of the MB cationic dye which is strongly adsorbed onto the negatively charged sitinakite surfaces.},
	number = {26},
	journal = {Chemistry of materials},
	author = {Luca, Vittorio and Osborne, Michael A. and Sizgek, Devlet and Griffith, Christopher and Araujo, Paula Z.},
	year = {2006},
	pages = {6132--6138},
}

@article{gibson_gaussian_2012,
	title = {A {Gaussian} process framework for modelling instrumental systematics: application to transmission spectroscopy},
	volume = {419},
	doi = {10.1111/j.1365-2966.2011.19915.x},
	abstract = {Transmission spectroscopy, which consists of measuring the wavelength-dependent absorption of starlight by a planet’s atmosphere during a transit, is a powerful probe of atmospheric composition. However, the expected signal is typically orders of magnitude smaller than instrumental systematics, and the results are crucially dependent on the treatment of the latter. In this paper, we propose a new method to infer transit parameters in the presence of systematic noise using Gaussian processes, a technique widely used in the machine learning community for Bayesian regression and classification problems. Our method makes use of auxiliary information about the state of the instrument, but does so in a non-parametric manner, without imposing a specific dependence of the systematics on the instrumental parameters, and naturally allows for the correlated nature of the noise. We give an example application of the method to archival NICMOS transmission spectroscopy of the hot Jupiter HD 189733, which goes some way towards reconciling the controversy surrounding this dataset in the literature. Finally, we provide an appendix giving a general introduction to Gaussian processes for regression, in order to encourage their application to a wider range of problems.},
	number = {3},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Gibson, Neale P. and Aigrain, Suzanne and Roberts, Stephen J. and Evans, Tom and Osborne, Michael A. and Pont, Frederic},
	year = {2012},
	pages = {2683--2694},
	file = {5857/Gibson et al_2012_A Gaussian process framework for modelling instrumental systematics.pdf},
}

@article{ng_using_2014,
	title = {Using textons to rank crystallization droplets by the likely presence of crystals},
	volume = {70},
	issn = {1399-0047},
	url = {http://scripts.iucr.org/cgi-bin/paper?S1399004714017581},
	doi = {10.1107/S1399004714017581},
	abstract = {The visual inspection of crystallization experiments is an important yet time-consuming and subjective step in X-ray crystallography. Previously published studies have focused on automatically classifying crystallization droplets into distinct but ultimately arbitrary experiment outcomes; here, a method is described that instead ranks droplets by their likelihood of containing crystals or microcrystals, thereby prioritizing for visual inspection those images that are most likely to contain useful information. The use of textons is introduced to describe crystallization droplets objectively, allowing them to be scored with the posterior probability of a random forest classifier trained against droplets manually annotated for the presence or absence of crystals or microcrystals. Unlike multi- class classification, this two-class system lends itself naturally to unidirectional ranking, which is most useful for assisting sequential viewing because images can be arranged simply by using these scores: this places droplets with probable crystal- line behaviour early in the viewing order. Using this approach, the top ten wells included at least one human-annotated crystal or microcrystal for 94\% of the plates in a data set of 196 plates imaged with a Minstrel HT system. The algorithm is robustly transferable to at least one other imaging system: when the parameters trained from Minstrel HT images are applied to a data set imaged by the Rock Imager system, human-annotated crystals ranked in the top ten wells for 90\% of the plates. Because rearranging images is fundamental to the approach, a custom viewer was written to seamlessly support such ranked viewing, along with another important output of the algorithm, namely the shape of the curve of scores, which is itself a useful overview of the behaviour of the plate; additional features with known usefulness were adopted from existing viewers. Evidence is presented that such ranked viewing of images allows faster but more accurate evaluation of drops, in particular for the identification of microcrystals.},
	number = {10},
	journal = {Acta Crystallographica Section D Biological Crystallography},
	author = {Ng, Jia Tsing and Dekker, Carien and Kroemer, Markus and Osborne, Michael A. and von Delft, Frank},
	month = oct,
	year = {2014},
	file = {5688/Ng et al_2014_Using textons to rank crystallization droplets by the likely presence of.pdf},
}

@article{richardson_gaussian_2017,
	title = {Gaussian process regression for forecasting battery state of health},
	volume = {357},
	issn = {0378-7753},
	url = {http://www.sciencedirect.com/science/article/pii/S0378775317306250},
	doi = {10.1016/j.jpowsour.2017.05.004},
	abstract = {Accurately predicting the future capacity and remaining useful life of batteries is necessary to ensure reliable system operation and to minimise maintenance costs. The complex nature of battery degradation has meant that mechanistic modelling of capacity fade has thus far remained intractable; however, with the advent of cloud-connected devices, data from cells in various applications is becoming increasingly available, and the feasibility of data-driven methods for battery prognostics is increasing. Here we propose Gaussian process (GP) regression for forecasting battery state of health, and highlight various advantages of GPs over other data-driven and mechanistic approaches. GPs are a type of Bayesian non-parametric method, and hence can model complex systems whilst handling uncertainty in a principled manner. Prior information can be exploited by GPs in a variety of ways: explicit mean functions can be used if the functional form of the underlying degradation model is available, and multiple-output GPs can effectively exploit correlations between data from different cells. We demonstrate the predictive capability of GPs for short-term and long-term (remaining useful life) forecasting on a selection of capacity vs. cycle datasets from lithium-ion cells.},
	journal = {Journal of Power Sources},
	author = {Richardson, Robert R. and Osborne, Michael A. and Howey, David A.},
	month = jul,
	year = {2017},
	keywords = {Ageing, Gaussian process regression, Lithium-ion battery, Prognostics, State-of-health},
	pages = {209--219},
	file = {5311/Richardson et al_2017_Gaussian process regression for forecasting battery state of health.pdf},
}

@article{osborne_real-time_2012,
	title = {Real-{Time} {Information} {Processing} of {Environmental} {Sensor} {Network} {Data}},
	volume = {9},
	doi = {10.1145/2379799.2379800},
	abstract = {In this paper, we consider the problem faced by a sensor network operator who must infer, in real-time, the value of some environmental parameter that is being monitored at discrete points in space and time by a sensor network. We describe a powerful and generic approach built upon an efficient multi-output Gaussian process that facilitates this information acquisition and processing. Our algorithm allows effective inference even with minimal domain knowledge, and we further introduce a formulation of Bayesian Monte Carlo to permit the principled management of the hyperparameters introduced by our flexible models. We demonstrate how our methods can be applied in cases where the data is delayed, intermittently missing, censored and/or correlated. We validate our approach using data collected from three networks of weather sensors and show that it yields better inference performance than both conventional independent Gaussian processes and the Kalman filter. Finally, we show that our formalism efficiently re-uses previous computations by following an online update procedure as new data sequentially arrives, and that this results in a four-fold increase in computational speed in the largest cases considered.},
	number = {1},
	journal = {ACM Transactions on Sensor Networks},
	author = {Osborne, Michael A. and Roberts, Stephen J. and Rogers, Alex and Jennings, Nicholas R.},
	year = {2012},
	pages = {1:1--1:32},
	file = {5841/Osborne et al_2012_Real-Time Information Processing of Environmental Sensor Network Data.pdf},
}

@article{roberts_gaussian_2013,
	title = {Gaussian processes for time-series modelling},
	volume = {371},
	doi = {10.1098/rsta.2011.0550},
	abstract = {In this paper we offer a gentle introduction to Gaussian processes for timeseries data analysis. The conceptual framework of Bayesian modelling for timeseries data is discussed and the foundations of Bayesian non-parametric modelling presented for Gaussian processes. We discuss how domain knowledge influences design of the Gaussian process models and provide case examples to highlight the approaches.},
	number = {1984},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Roberts, Stephen J. and Osborne, Michael A. and Ebden, Mark and Reece, Steve and Gibson, Neale P. and Aigrain, Suzanne},
	year = {2013},
	pages = {20110550},
	file = {5807/Roberts et al_2013_Gaussian processes for time-series modelling.pdf},
}

@article{mann_objectively_2011,
	title = {Objectively identifying landmark use and predicting flight trajectories of the homing pigeon using {Gaussian} processes},
	volume = {8},
	doi = {10.1098/rsif.2010.0301},
	abstract = {Pigeons home along idiosyncratic habitual routes from familiar locations. It has been suggested that memorized visual landmarks underpin this route learning. However, the inability to experimentally alter the landscape on large scales has hindered the discovery of the particular features to which birds attend. Here, we present a method for objectively classifying the most informative regions of animal paths. We apply this method to flight trajectories from homing pigeons to identify probable locations of salient visual landmarks. We construct and apply a Gaussian process model of flight trajectory generation for pigeons trained to home from specific release sites. The model shows increasing predictive power as the birds become familiar with the sites, mirroring the animal’s learning process. We subsequently find that the most informative elements of the flight trajectories coincide with landscape features that have previously been suggested as important components of the homing task.},
	number = {55},
	journal = {Journal of The Royal Society Interface},
	author = {Mann, Richard and Freeman, Robin and Osborne, Michael A. and Garnett, Roman and Armstrong, Chris and Meade, Jessica and Biro, Dora and Guilford, Tim and Roberts, Stephen J.},
	year = {2011},
	pages = {210--219},
	file = {5874/Mann et al_2011_Objectively identifying landmark use and predicting flight trajectories of the.pdf},
}

@article{frey_future_2017,
	title = {The future of employment: {How} susceptible are jobs to computerisation?},
	volume = {114},
	issn = {0040-1625},
	shorttitle = {The future of employment},
	url = {http://www.sciencedirect.com/science/article/pii/S0040162516302244},
	doi = {10.1016/j.techfore.2016.08.019},
	abstract = {We examine how susceptible jobs are to computerisation. To assess this, we begin by implementing a novel methodology to estimate the probability of computerisation for 702 detailed occupations, using a Gaussian process classifier. Based on these estimates, we examine expected impacts of future computerisation on US labour market outcomes, with the primary objective of analysing the number of jobs at risk and the relationship between an occupations probability of computerisation, wages and educational attainment.},
	journal = {Technological Forecasting and Social Change},
	author = {Frey, Carl Benedikt and Osborne, Michael A.},
	month = jan,
	year = {2017},
	keywords = {Employment, Occupational choice, Skill demand, Technological change, wage inequality},
	pages = {254--280},
	file = {5383/Frey_Osborne_2017_The future of employment.pdf},
}

@article{zhang_spatial_2018,
	title = {Spatial {Field} {Reconstruction} and {Sensor} {Selection} in {Heterogeneous} {Sensor} {Networks} with {Stochastic} {Energy} {Harvesting}},
	url = {http://arxiv.org/abs/1801.05356},
	abstract = {We address the two fundamental problems of spatial field reconstruction and sensor selection in het- erogeneous sensor networks. We consider the case where two types of sensors are deployed: the first consists of expensive, high quality sensors; and the second, of cheap low quality sensors, which are activated only if the intensity of the spatial field exceeds a pre-defined activation threshold (eg. wind sensors). In addition, these sensors are powered by means of energy harvesting and their time varying energy status impacts on the accuracy of the measurement that may be obtained. We account for this phenomenon by encoding the energy harvesting process into the second moment properties of the additive noise, resulting in a spatial heteroscedastic process. We then address the following two important problems: (i) how to efficiently perform spatial field reconstruction based on measurements obtained simultaneously from both networks; and (ii) how to perform query based sensor set selection with predictive MSE performance guarantee. We first show that the resulting predictive posterior distribution, which is key in fusing such disparate observations, involves solving intractable integrals. To overcome this problem, we solve the first problem by developing a low complexity algorithm based on the spatial best linear unbiased estimator (S-BLUE). Next, building on the S-BLUE, we address the second problem, and develop an efficient algorithm for query based sensor set selection with performance guarantee. Our algorithm is based on the Cross Entropy method which solves the combinatorial optimization problem in an efficient manner. We present a comprehensive study of the performance gain that can be obtained by augmenting the high-quality sensors with low-quality sensors using both synthetic and real insurance storm surge database known as the Extreme Wind Storms Catalogue.},
	journal = {IEEE Transactions on Signal Processing},
	author = {Zhang, Pengfei and Nevat, Ido and Peters, Gareth W. and Septier, Francois and Osborne, Michael A.},
	year = {2018},
	keywords = {Electrical Engineering and Systems Science - Signal Processing},
	file = {5279/Zhang et al_2018_Spatial Field Reconstruction and Sensor Selection in Heterogeneous Sensor.pdf},
}

@article{richardson_gaussian_2018,
	title = {Gaussian {Process} {Regression} for {In}-situ {Capacity} {Estimation} of {Lithium}-ion {Batteries}},
	issn = {1551-3203, 1941-0050},
	url = {http://ieeexplore.ieee.org/document/8263147/},
	doi = {10.1109/TII.2018.2794997},
	abstract = {Accurate on-board capacity estimation is of critical importance in lithium-ion battery applications. Battery charg- ing/discharging often occurs under a constant current load, and hence voltage vs. time measurements under this condition may be accessible in practice. This paper presents a data-driven diagnostic technique, Gaussian Process regression for In-situ Capacity Estimation (GP-ICE), which estimates battery capacity using voltage measurements over short periods of galvanostatic operation. Unlike previous works, GP-ICE does not rely on interpreting the voltage-time data as Incremental Capacity (IC) or Differential Voltage (DV) curves. This overcomes the need to differentiate the voltage-time data (a process which amplifies measurement noise), and the requirement that the range of voltage measurements encompasses the peaks in the IC/DV curves. GP-ICE is applied to two datasets, consisting of 8 and 20 cells respectively. In each case, within certain voltage ranges, as little as 10 seconds of galvanostatic operation enables capacity estimates with approximately 2–3 \% RMSE.},
	urldate = {2018-01-19},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Richardson, Robert R. and Birkl, Christoph R. and Osborne, Michael A. and Howey, David},
	year = {2018},
	pages = {1--1},
	file = {5284/Richardson et al_2018_Gaussian Process Regression for In-situ Capacity Estimation of Lithium-ion.pdf},
}

@article{sarkar_prediction_2018,
	title = {Prediction of tidal currents using {Bayesian} machine learning},
	volume = {158},
	issn = {0029-8018},
	url = {https://www.sciencedirect.com/science/article/pii/S0029801818302397},
	doi = {10.1016/j.oceaneng.2018.03.007},
	abstract = {We propose the use of machine learning techniques in the Bayesian framework for the prediction of tidal currents. Computer algorithms based on the classical harmonic analysis approach have been used for several decades in tidal predictions, however the method has several limitations in terms of handling of noise, expressing uncertainty, capturing non-sinusoidal, non-harmonic variations. There is a need for principled approaches which can handle uncertainty and accommodate noise in the data. In this work, we use Gaussian processes, a Bayesian non-parametric machine learning technique, to predict tidal currents. The probabilistic and non-parametric nature of the approach enables it to represent uncertainties in modelling and deal with complexities of the problem. The method makes use of kernel functions to capture structures in the data. The overall objective is to take advantage of the recent progress in machine learning to construct a robust algorithm. Using several sets of field data, we show that the machine learning approach can achieve better results than the traditional approaches.},
	urldate = {2018-04-13},
	journal = {Ocean Engineering},
	author = {Sarkar, Dripta and Osborne, Michael A. and Adcock, Thomas A. A.},
	month = jun,
	year = {2018},
	keywords = {Gaussian process, Machine learning, Prediction, Tidal currents},
	pages = {221--231},
	file = {5211/Sarkar et al_2018_Prediction of tidal currents using Bayesian machine learning.pdf},
}

@article{lee_optimal_2018,
	title = {Optimal operation of an energy management system using model predictive control and {Gaussian} process time-series modelling},
	issn = {2168-6777},
	url = {https://ieeexplore.ieee.org/document/8327585},
	doi = {10.1109/JESTPE.2018.2820071},
	abstract = {This paper describes an optimal operation scheme for energy management systems (EMS) using Gaussian process (GP) forecasting and model predictive control (MPC) in the context of grid-connected microgrids with local generation, loads and storage. The main objective of the control is to minimize the cost of energy taken from the grid. The microgrid consists of a PV panel and a battery energy storage system (ESS), which are connected to a power grid and a local load via a DC bus. At each sampling time, the predictions for PV output power and load demand power are calculated, and an MPC algorithm is executed based on these predictions and a physical battery model to decide the setpoint of the battery. Simulations of two case studies, namely, a lab scale microgrid and a commercial microgrid, are presented. We compare the performance of MPC with various horizon lengths to a rule-based control strategy to demonstrate a cost reduction of more than than 2\%.},
	journal = {IEEE J. Emerg. Sel. Topics Power Electron. IEEE Journal of Emerging and Selected Topics in Power Electronics},
	author = {Lee, Jaehwa and Zhang, Pengfei and Gan, Leong Kit and Howey, David A and Osborne, Michael A and Tosi, Alessandra and Duncan, Stephen},
	year = {2018},
	pages = {1},
	file = {5286/Lee et al_2018_Optimal operation of an energy management system using model predictive control.pdf},
}

@article{richardson_battery_2019,
	title = {Battery health prediction under generalized conditions using a {Gaussian} process transition model},
	volume = {23},
	issn = {2352-152X},
	url = {http://www.sciencedirect.com/science/article/pii/S2352152X18307734},
	doi = {10.1016/j.est.2019.03.022},
	abstract = {Accurately predicting the future health of batteries is necessary to ensure reliable operation, minimise maintenance costs, and calculate the value of energy storage investments. The complex nature of degradation renders data-driven approaches a promising alternative to mechanistic modelling. Here we show that a Bayesian non-parametric approach, using Gaussian process regression, can predict capacity fade in a variety of usage scenarios, forming a generalised health model. Our results are demonstrated on the open-source NASA Randomised Battery Usage Dataset, with data of 26 cells aged under widely varying operational conditions. Using half of the cells for training, and half for validation, we can accurately predict long term capacity fade, with a best case normalised root mean square error of 4.3\%, including accurate estimation of the uncertainty of the prediction.},
	urldate = {2019-04-23},
	journal = {Journal of Energy Storage},
	author = {Richardson, Robert R. and Osborne, Michael A. and Howey, David A.},
	month = jun,
	year = {2019},
	keywords = {Gaussian process regression, Prognostics, Battery, Degradation, Health, Lithium-ion},
	pages = {320--328},
	file = {5132/Richardson et al_2019_Battery health prediction under generalized conditions using a Gaussian process.pdf},
}

@article{sarkar_spatiotemporal_2019,
	title = {Spatiotemporal {Prediction} of {Tidal} {Currents} {Using} {Gaussian} {Processes}},
	volume = {124},
	issn = {2169-9275},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018JC014471},
	doi = {10.1029/2018JC014471},
	abstract = {Abstract Predicting fast tidal currents can be a challenging task. Unlike tidal water levels, currents can vary sharply over short distances. The classical approach of harmonic analysis can analyze data at point locations and there is a need for a method that can handle spatiotemporal data, as well as be robust to the uncertainty and noise inevitable in real-world measurements. In this work, we present a Bayesian machine learning (ML) approach to tackle the problem. The method is based on Gaussian processes, a nonparametric ML technique that uses a kernel function to capture structures in the data. A case study is performed using data from a validated numerical model simulating the tidal dynamics in the Pentland Firth region, UK. Several sampling strategies are explored and the case where measurement location is changed after every sampling is found to produce the lowest average error in the predictions. We show that the presented methodology using data from just a single moving data source can provide a better spatiotemporal description than traditional techniques using continuous data from a large number of locations. The work can be useful to developers of tidal energy farms, navigation, and other purposes.},
	number = {4},
	urldate = {2019-04-23},
	journal = {Journal of Geophysical Research: Oceans},
	author = {Sarkar, Dripta and Osborne, Michael A. and Adcock, Thomas A. A.},
	month = mar,
	year = {2019},
	keywords = {Gaussian process, machine learning, data sampling, oceanography, spatiotemporal modeling, tidal currents},
	pages = {2697--2715},
	file = {5158/Sarkar et al_2019_Spatiotemporal Prediction of Tidal Currents Using Gaussian Processes.pdf},
}

@article{briol_rejoinder_2019,
	title = {Rejoinder – {Probabilistic} {Integration}: {A} {Role} in {Statistical} {Computation}?},
	volume = {34},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Rejoinder},
	url = {https://projecteuclid.org/euclid.ss/1555056029},
	doi = {10.1214/18-STS683},
	abstract = {This article is the rejoinder for the paper “Probabilistic Integration: A Role in Statistical Computation?” (Statist. Sci. 34 (2019) 1–22). We would first like to thank the reviewers and many of our colleagues who helped shape this paper, the Editor for selecting our paper for discussion, and of course all of the discussants for their thoughtful, insightful and constructive comments. In this rejoinder, we respond to some of the points raised by the discussants and comment further on the fundamental questions underlying the paper: (i) Should Bayesian ideas be used in numerical analysis? and (ii) If so, what role should such approaches have in statistical computation?},
	language = {EN},
	number = {1},
	urldate = {2019-04-23},
	journal = {Statistical Science},
	author = {Briol, François-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A. and Sejdinovic, Dino},
	month = feb,
	year = {2019},
	keywords = {probabilistic numerics, Computational statistics, nonparametric statistics, uncertainty quantification},
	pages = {38--42},
	file = {5170/Briol et al_2019_Rejoinder – Probabilistic Integration.pdf},
}

@article{briol_probabilistic_2019,
	title = {Probabilistic {Integration}: {A} {Role} in {Statistical} {Computation}?},
	volume = {34},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Probabilistic {Integration}},
	url = {http://arxiv.org/abs/1512.00933},
	doi = {10.1214/18-STS660},
	abstract = {A research frontier has emerged in scientific computation, wherein discretisation error is regarded as a source of epistemic uncertainty that can be modelled. This raises several statistical challenges, including the design of statistical methods that enable the coherent propagation of probabilities through a (possibly deterministic) computational work-flow, in order to assess the impact of discretisation error on the computer output. This paper examines the case for probabilistic numerical methods in routine statistical computation. Our focus is on numerical integration, where a probabilistic integrator is equipped with a full distribution over its output that reflects the fact that the integrand has been discretised. Our main technical contribution is to establish, for the first time, rates of posterior contraction for one such method. Several substantial applications are provided for illustration and critical evaluation, including examples from statistical modelling, computer graphics and a computer model for an oil reservoir.},
	language = {EN},
	number = {1},
	urldate = {2019-04-23},
	journal = {Statistical Science},
	author = {Briol, François-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A. and Sejdinovic, Dino},
	month = feb,
	year = {2019},
	note = {https://fxbriol.github.io/publications/www.warwick.ac.uk/fxbriol/probabilistic\_integration/code\_pi\_mar16.zip},
	keywords = {probabilistic numerics, Computational statistics, nonparametric statistics, uncertainty quantification},
	pages = {1--22},
	file = {5171/Briol et al_2019_Probabilistic Integration.pdf},
}

@article{granziol_meme:_2019,
	title = { {MEMe}: {An} {Accurate} {Maximum} {Entropy} {Method} for {Efficient} {Approximations} in {Large}-{Scale} {Machine} {Learning}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = { {MEMe}},
	url = {https://www.mdpi.com/1099-4300/21/6/551},
	doi = {10.3390/e21060551},
	abstract = {Efficient approximation lies at the heart of large-scale machine learning problems. In this paper, we propose a novel, robust maximum entropy algorithm, which is capable of dealing with hundreds of moments and allows for computationally efficient approximations. We showcase the usefulness of the proposed method, its equivalence to constrained Bayesian variational inference and demonstrate its superiority over existing approaches in two applications, namely, fast log determinant estimation and information-theoretic Bayesian optimisation.},
	language = {en},
	number = {6},
	urldate = {2019-05-31},
	journal = {Entropy},
	author = {Granziol, Diego and Ru, Binxin and Zohren, Stefan and Dong, Xiaowen and Osborne, Michael and Roberts, Stephen},
	month = jun,
	year = {2019},
	keywords = {Bayesian optimisation, log determinant estimation, maximum entropy},
	pages = {551},
	file = {5133/Granziol et al_2019_MEMe.pdf},
}

@article{lennon_efficiently_2019,
	title = {Efficiently measuring a quantum device using machine learning},
	volume = {5},
	copyright = {2019 The Author(s)},
	issn = {2056-6387},
	url = {https://www.nature.com/articles/s41534-019-0193-4},
	doi = {10.1038/s41534-019-0193-4},
	abstract = {Scalable quantum technologies such as quantum computers will require very large numbers of quantum devices to be characterised and tuned. As the number of devices on chip increases, this task becomes ever more time-consuming, and will be intractable on a large scale without efficient automation. We present measurements on a quantum dot device performed by a machine learning algorithm in real time. The algorithm selects the most informative measurements to perform next by combining information theory with a probabilistic deep-generative model that can generate full-resolution reconstructions from scattered partial measurements. We demonstrate, for two different current map configurations that the algorithm outperforms standard grid scan techniques, reducing the number of measurements required by up to 4 times and the measurement time by 3.7 times. Our contribution goes beyond the use of machine learning for data search and analysis, and instead demonstrates the use of algorithms to automate measurements. This works lays the foundation for learning-based automated measurement of quantum devices.},
	language = {en},
	number = {1},
	urldate = {2019-09-29},
	journal = {npj Quantum Information},
	author = {Lennon, D. T. and Moon, H. and Camenzind, L. C. and Yu, Liuqi and Zumbühl, D. M. and Briggs, G. a. D. and Osborne, M. A. and Laird, E. A. and Ares, N.},
	month = sep,
	year = {2019},
	pages = {1--8},
	file = {5118/Lennon et al_2019_Efficiently measuring a quantum device using machine learning.pdf},
}

@article{fitzsimons_general_2019,
	title = {A {General} {Framework} for {Fair} {Regression}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1099-4300/21/8/741},
	doi = {10.3390/e21080741},
	abstract = {Fairness, through its many forms and definitions, has become an important issue facing the machine learning community. In this work, we consider how to incorporate group fairness constraints into kernel regression methods, applicable to Gaussian processes, support vector machines, neural network regression and decision tree regression. Further, we focus on examining the effect of incorporating these constraints in decision tree regression, with direct applications to random forests and boosted trees amongst other widespread popular inference techniques. We show that the order of complexity of memory and computation is preserved for such models and tightly binds the expected perturbations to the model in terms of the number of leaves of the trees. Importantly, the approach works on trained models and hence can be easily applied to models in current use and group labels are only required on training data.},
	language = {en},
	number = {8},
	urldate = {2019-09-29},
	journal = {Entropy},
	author = {Fitzsimons, Jack and Al Ali, AbdulRahman and Osborne, Michael and Roberts, Stephen},
	month = aug,
	year = {2019},
	keywords = {Gaussian process, machine learning, kernel methods, algorithmic fairness, constrained learning, decision tree, neural network},
	pages = {741},
	file = {5122/Fitzsimons et al_2019_A General Framework for Fair Regression.pdf},
}

@article{zhao_quantum_2019,
	title = {Quantum algorithms for training {Gaussian} processes},
	volume = {100},
	url = {https://link.aps.org/doi/10.1103/PhysRevA.100.012304},
	doi = {10.1103/PhysRevA.100.012304},
	abstract = {Gaussian processes (GPs) are important models in supervised machine learning. Training in Gaussian processes refers to selecting the covariance functions and the associated parameters in order to improve the outcome of predictions, the core of which amounts to evaluating the logarithm of the marginal likelihood (LML) of a given model. The LML gives a concrete measure of the quality of prediction that a GP model is expected to achieve. The classical computation of the LML typically carries a polynomial time overhead with respect to the input size. We propose a quantum algorithm that computes the logarithm of the determinant of a Hermitian matrix, which runs in logarithmic time for sparse matrices. This is applied in conjunction with a variant of the quantum linear system algorithm that allows for logarithmic-time computation of the form yTA−1y, where y is a dense vector and A is the covariance matrix. We hence show that quantum computing can be used to estimate the LML of a GP with exponentially improved efficiency under certain conditions.},
	number = {1},
	urldate = {2019-09-29},
	journal = {Physical Review A},
	author = {Zhao, Zhikuan and Fitzsimons, Jack K. and Osborne, Michael A. and Roberts, Stephen J. and Fitzsimons, Joseph F.},
	month = jul,
	year = {2019},
	pages = {012304},
	file = {5125/Zhao et al_2019_Quantum algorithms for training Gaussian processes.pdf},
}

@article{willis_qualitative_2020,
	title = {Qualitative and quantitative approach to assess of the potential for automating administrative tasks in general practice},
	volume = {10},
	copyright = {© Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by-nc/4.0/This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
	issn = {2044-6055, 2044-6055},
	url = {https://bmjopen.bmj.com/content/10/6/e032412},
	doi = {10.1136/bmjopen-2019-032412},
	abstract = {Objective To identify the extent to which administrative tasks carried out by primary care staff in general practice could be automated.
Design A mixed-method design including ethnographic case studies, focus groups, interviews and an online survey of automation experts.
Setting Three urban and three rural general practice health centres in England selected for differences in list size and organisational characteristics.
Participants Observation and interviews with 65 primary care staff in the following job roles: administrator, manager, general practitioner, healthcare assistant, nurse practitioner, pharmacy technician, phlebotomist, practice nurse, pharmacist, prescription clerk, receptionist, scanning clerk, secretary and medical summariser; together with a survey of 156 experts in automation technologies.
Methods 330 hours of ethnographic observation and documentation of administrative tasks carried out by staff in each of the above job roles, followed by coding and classification; semistructured interviews with 10 general practitioners and 6 staff focus groups. The online survey of machine learning, artificial intelligence and robotics experts was analysed using an ordinal Gaussian process prediction model to estimate the automatability of the observed tasks.
Results The model predicted that roughly 44\% of administrative tasks carried out by staff in general practice are ‘mostly’ or ‘completely’ automatable using currently available technology. Discussions with practice staff underlined the need for a cautious approach to implementation.
Conclusions There is considerable potential to extend the use of automation in primary care, but this will require careful implementation and ongoing evaluation.},
	language = {en},
	number = {6},
	urldate = {2020-06-16},
	journal = {BMJ Open},
	author = {Willis, Matthew and Duckworth, Paul and Coulter, Angela and Meyer, Eric T. and Osborne, Michael},
	month = jun,
	year = {2020},
	keywords = {machine learning, automation, office, health policy, organisation of health services, primary care},
	pages = {e032412},
	file = {6037/Willis et al. - 2020 - Qualitative and quantitative approach to assess of.pdf},
}

@article{nguyen_deep_2021,
	title = {Deep reinforcement learning for efficient measurement of quantum devices},
	volume = {7},
	copyright = {2021 The Author(s)},
	issn = {2056-6387},
	url = {https://www.nature.com/articles/s41534-021-00434-x},
	doi = {10.1038/s41534-021-00434-x},
	abstract = {Deep reinforcement learning is an emerging machine-learning approach that can teach a computer to learn from their actions and rewards similar to the way humans learn from experience. It offers many advantages in automating decision processes to navigate large parameter spaces. This paper proposes an approach to the efficient measurement of quantum devices based on deep reinforcement learning. We focus on double quantum dot devices, demonstrating the fully automatic identification of specific transport features called bias triangles. Measurements targeting these features are difficult to automate, since bias triangles are found in otherwise featureless regions of the parameter space. Our algorithm identifies bias triangles in a mean time of {\textless}30 min, and sometimes as little as 1 min. This approach, based on dueling deep Q-networks, can be adapted to a broad range of devices and target transport features. This is a crucial demonstration of the utility of deep reinforcement learning for decision making in the measurement and operation of quantum devices.},
	language = {en},
	number = {1},
	urldate = {2021-08-11},
	journal = {npj Quantum Information},
	author = {Nguyen, V. and Orbell, S. B. and Lennon, D. T. and Moon, H. and Vigneau, F. and Camenzind, L. C. and Yu, L. and Zumbühl, D. M. and Briggs, G. a. D. and Osborne, M. A. and Sejdinovic, D. and Ares, N.},
	month = jun,
	year = {2021},
	note = {https://github.com/oxquantum-repo/drl\_for\_quantum\_measurement},
	pages = {1--9},
	file = {6568/Nguyen et al_2021_Deep reinforcement learning for efficient measurement of quantum devices.pdf},
}

@article{moon_machine_2020,
	title = {Machine learning enables completely automatic tuning of a quantum device faster than human experts},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-17835-9},
	doi = {10.1038/s41467-020-17835-9},
	abstract = {Variability is a problem for the scalability of semiconductor quantum devices. The parameter space is large, and the operating range is small. Our statistical tuning algorithm searches for specific electron transport features in gate-defined quantum dot devices with a gate voltage space of up to eight dimensions. Starting from the full range of each gate voltage, our machine learning algorithm can tune each device to optimal performance in a median time of under 70 minutes. This performance surpassed our best human benchmark (although both human and machine performance can be improved). The algorithm is approximately 180 times faster than an automated random search of the parameter space, and is suitable for different material systems and device architectures. Our results yield a quantitative measurement of device variability, from one device to another and after thermal cycling. Our machine learning algorithm can be extended to higher dimensions and other technologies.},
	language = {en},
	number = {1},
	urldate = {2021-08-11},
	journal = {Nature Communications},
	author = {Moon, H. and Lennon, D. T. and Kirkpatrick, J. and van Esbroeck, N. M. and Camenzind, L. C. and Yu, Liuqi and Vigneau, F. and Zumbühl, D. M. and Briggs, G. a. D. and Osborne, M. A. and Sejdinovic, D. and Laird, E. A. and Ares, N.},
	month = aug,
	year = {2020},
	pages = {4161},
	file = {6604/Moon et al_2020_Machine learning enables completely automatic tuning of a quantum device faster2.pdf},
}

@article{gan_data-driven_2021,
	title = {Data-{Driven} {Energy} {Management} {System} {With} {Gaussian} {Process} {Forecasting} and {MPC} for {Interconnected} {Microgrids}},
	volume = {12},
	issn = {1949-3037},
	doi = {10.1109/TSTE.2020.3017224},
	abstract = {Interest in predicting and optimising microgrid operation with a high proportion of variable renewable energy generation is growing. In this paper, we study and experimentally analyse the performance of a Gaussian-process regression forecasting and model predictive control algorithm in the context of interconnected microgrids. The scheme, which operated at six hours time horizon, achieved superior results with only a small deviation from the optimal operation calculated offline assuming perfect foresight. We also demonstrate that whilst a longer horizon provides a better solution in terms of lower cost of electricity, the battery cycling rate is also higher. Finally, we demonstrate improvements in renewable and load forecasts by sharing information between the microgrids.},
	number = {1},
	journal = {IEEE Transactions on Sustainable Energy},
	author = {Gan, Leong Kit and Zhang, PengFei and Lee, Jaehwa and Osborne, Michael A. and Howey, David A.},
	month = jan,
	year = {2021},
	keywords = {Batteries, battery, Energy management, energy management systems, Forecasting, Gaussian processes, Microgrids, MPC, optimisation, Optimization, Prediction algorithms, predictions},
	pages = {695--704},
	file = {6608/Gan et al_2021_Data-Driven Energy Management System With Gaussian Process Forecasting and MPC.pdf},
}

@inproceedings{mann_gaussian_2009,
	title = {Gaussian {Processes} for {Prediction} of {Homing} {Pigeon} {Flight} {Trajectories}},
	volume = {1193},
	doi = {10.1063/1.3275635},
	abstract = {We construct and apply a stochastic Gaussian Process (GP) model of flight trajectory generation for pigeons trained to home from specific release sites. The model shows increasing pre- dictive power as the birds become familiar with the sites, mirroring the animal’s learning process. We show how the increasing similarity between successive flight trajectories can be used to infer, with increasing accuracy, an idealised route that captures the repeated spatial aspects of the bird’s flight. We subsequently use techniques associated with reduced-rank GP approximations to objec- tively identify the key waypoints used by each bird to memorise its idiosyncratic habitual route between the release site and the home loft.},
	booktitle = { {AIP} {Conference} {Proceedings}},
	author = {Mann, Richard and Freeman, Robin and Osborne, Michael A. and Garnett, Roman and Meade, Jessica and Armstrong, Chris and Biro, Dora and Guilford, Tim and Roberts, Stephen J. and Goggans, Paul M.},
	year = {2009},
	pages = {360},
	file = {5930/Mann et al_2009_Gaussian Processes for Prediction of Homing Pigeon Flight Trajectories.pdf},
}

@inproceedings{calliess_conservative_2014,
	title = {Conservative collision prediction and avoidance for stochastic trajectories in continuous time and space},
	isbn = {1-4503-2738-9},
	abstract = {Existing work in multi-agent collision prediction and avoidance typically assumes discrete-time tra jectories with Gaussian uncertainty or that are completely deterministic. We propose an approach that allows detection of collisions even between continuous, stochastic trajectories with the only restriction that means and covariances can be computed. To this end, we employ probabilistic bounds to derive criterion functions whose nega tive sign provably is indicative of probable colli sions. For criterion functions that are Lipschitz, an algorithm is provided to rapidly find negative values or prove their absence. We propose an iterative policy-search approach that avoids prior discretisations and yields collision-free trajectories with adjustably high certainty. We test our method with both fixed-priority and auction based protocols for coordinating the iterative plan ning process. Results are provided in collision avoidance simulations of feedback controlled plants.},
	booktitle = {Proceedings of the 2014 international conference on {Autonomous} agents and multi-agent systems ({AAMAS})},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Calliess, Jan-Peter and Osborne, Michael A. and Roberts, Stephen J.},
	year = {2014},
	pages = {1109--1116},
	file = {5774/Calliess et al_2014_Conservative collision prediction and avoidance for stochastic trajectories in.pdf},
}

@inproceedings{osborne_active_2010,
	title = {Active data selection for sensor networks with faults and changepoints},
	isbn = {1-4244-6695-4},
	abstract = {We describe a Bayesian formalism for the intelligent selection of observations from sensor networks that may intermittently undergo faults or changepoints. Such active data selection is performed with the goal of taking as few observations as necessary in order to maintain a reasonable level of uncertainty about the variables of interest. The presence of faults/changepoints is not always obvious and therefore our algorithm must first detect their occurrence. Having done so, our selection of observations must be appropriately altered. Faults corrupt our observations, reducing their impact; changepoints (abrupt changes in the characteristics of data) may require the transition to an entirely different sampling schedule. Our solution is to employ a Gaussian process formalism that allows for sequential time-series prediction about variables of interest along with a decision theoretic approach to the problem of selecting observations.},
	booktitle = {Advanced {Information} {Networking} and {Applications} ({AINA}), 2010 24th {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Osborne, Michael A. and Garnett, Roman and Roberts, Stephen J.},
	year = {2010},
	pages = {533--540},
	file = {5901/Osborne et al_2010_Active data selection for sensor networks with faults and changepoints.pdf},
}

@inproceedings{mathibela_can_2012,
	title = {Can priors be trusted? learning to anticipate roadworks},
	isbn = {1-4673-3064-7},
	abstract = {This paper addresses the question of how much a previously obtained map of a road environment should be trusted for vehicle localisation, during autonomous driving, by assessing the probability that roadworks are being traversed. We compare two formulations of a roadwork prior: one based on Gaussian Process (GP) Classification and the other a more conventional Hidden Markov Model (HMM) in order to model correlations between nearby parts of a vehicle trajectory. Impor- tantly, our formulation allows this prior to be updated efficiently and repeatedly to gain an ever more accurate model of the environment over time. In the absence of, or in addition to, any in-situ observations, information from dedicated web resources can readily be incorporated into the framework. We evaluate our model using real data from an autonomous car and show that although the GP and HMM are roughly commensurate in terms of mapping roadworks, the GP provides a more powerful representation and lower prediction error. Our method allows us to truly map and anticipate roadworks on urban roads.},
	booktitle = {Intelligent {Transportation} {Systems} ({ITSC}), 2012 15th {International} {IEEE} {Conference} on},
	publisher = {IEEE},
	author = {Mathibela, Bonolo and Osborne, Michael A. and Posner, Ingmar and Newman, Paul},
	year = {2012},
	pages = {927--932},
	file = {5847/Mathibela et al_2012_Can priors be trusted.pdf},
}

@inproceedings{rogers_information_2008,
	title = {Information agents for pervasive sensor networks},
	isbn = {0-7695-3113-X},
	abstract = {In this paper, we describe an information agent, that resides on a mobile computer or personal digital assistant (PDA), that can autonomously acquire sensor readings from pervasive sensor networks (deciding when and which sensor to acquire readings from at any time). Moreover, it can perform a range of information processing tasks including modelling the accuracy of the sensor readings, predicting the value of missing sensor readings, and predicting how the monitored environmental parameters will evolve into the future. Our motivating scenario is the need to provide situational awareness support to first responders at the scene of a large scale incident, and we describe how we use an iterative formulation of a multi-output Gaussian process to build a probabilistic model of the environmental parameters being measured by local sensors, and the correlations and delays that exist between them. We validate our approach using data collected from a network of weather sensors located on the south coast of England.},
	booktitle = {Pervasive {Computing} and {Communications}, 2008. {PerCom} 2008. {Sixth} {Annual} {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Rogers, Alex and Ramchurn, Sarvapali D. and Jennings, Nicholas R. and Osborne, Michael A. and Roberts, Stephen J.},
	year = {2008},
	pages = {294--299},
	file = {5941/Rogers et al_2008_Information agents for pervasive sensor networks.pdf},
}

@inproceedings{gunter_efficient_2014,
	title = {Efficient {Bayesian} {Nonparametric} {Modelling} of {Structured} {Point} {Processes}},
	url = {http://arxiv.org/abs/1407.6949},
	abstract = {This paper presents a Bayesian generative model for dependent Cox point processes, alongside an efficient inference scheme which scales as if the point processes were modelled independently. We can handle missing data naturally, infer latent structure, and cope with large numbers of observed processes. A further novel contribution enables the model to work effectively in higher dimensional spaces. Using this method, we achieve vastly improved predictive performance on both 2D and 1D real data, validating our structured approach.},
	booktitle = {30th {Conference} on {Uncertainty} in {Artificial} {Intelligence} ({UAI})},
	author = {Gunter, Tom and Lloyd, Chris and Osborne, Michael A. and Roberts, Stephen J.},
	year = {2014},
	file = {5760/Gunter et al_2014_Efficient Bayesian Nonparametric Modelling of Structured Point Processes.pdf},
}

@inproceedings{lloyd_latent_2016,
	title = {Latent {Point} {Process} {Allocation}},
	url = {http://jmlr.org/proceedings/papers/v51/lloyd16.html},
	abstract = {We introduce a probabilistic model for the factorisation of continuous Poisson process rate functions. Our model can be thought of as a topic model for Poisson point processes in which each point is assigned to one of a set of latent rate functions that are shared across multiple outputs. We show that the model brings a means of incorporating structure in point process inference beyond the state-of-the-art. We derive an efficient variational inference scheme for the model based on sparse Gaussian processes that scales linearly in the number of data points. Finally, we demonstrate, using examples from spatial and temporal statistics, how the model can be used for discovering hidden structure with greater precision than standard frequentist approaches.},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Artificial} {Intelligence} and {Statistics} ({AISTATS})},
	author = {Lloyd, Chris and Gunter, Tom and Osborne, Michael A. and Roberts, Stephen J. and Nickson, Tom},
	year = {2016},
	pages = {389--397},
	file = {5500/Lloyd et al_2016_Latent Point Process Allocation.pdf},
}

@inproceedings{garnett_active_2014,
	title = {Active {Learning} of {Linear} {Embeddings} for {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1310.6740},
	abstract = {We propose an active learning method for discovering low-dimensional structure in high-dimensional Gaussian process (GP) tasks. Such problems are increasingly frequent and important, but have hitherto presented severe practical difficulties. We further introduce a novel technique for approximately marginalizing GP hyperparameters, yielding marginal predictions robust to hyperparameter mis-specification. Our method offers an efficient means of performing GP regression, quadrature, or Bayesian optimization in high-dimensional spaces.},
	booktitle = {30th {Conference} on {Uncertainty} in {Artificial} {Intelligence} ({UAI})},
	author = {Garnett, Roman and Osborne, Michael A. and Hennig, Philipp},
	year = {2014},
	note = {https://is.gd/orezZh},
	file = {5764/Garnett et al_2014_Active Learning of Linear Embeddings for Gaussian Processes.pdf},
}

@inproceedings{osborne_prediction_2012,
	title = {Prediction and {Fault} {Detection} of {Environmental} {Signals} with {Uncharacterised} {Faults}.},
	abstract = {Many signals of interest are corrupted by faults of an unknown type. We propose an approach that uses Gaussian processes and a general “fault bucket” to capture a priori uncharacterised faults, along with an approximate method for marginalising the potential faultiness of all observations. This gives rise to an efficient, flexible algorithm for the detection and automatic correction of faults. Our method is deployed in the domain of water monitoring and management, where it is able to solve several fault detection, correction, and prediction problems. The method works well despite the fact that the data is plagued with numerous difficulties, including missing observations, multiple discontinuities, nonlinearity and many unanticipated types of fault.},
	booktitle = {The {Association} for the {Advancement} of {Artificial} {Intelligence} {Conference} {On} {Artificial} {Intelligence} ({AAAI})},
	author = {Osborne, Michael A. and Garnett, Roman and Swersky, Kevin and De Freitas, Nando},
	year = {2012},
	note = {https://is.gd/9M0ZYE},
	file = {5842/Osborne et al_2012_Prediction and Fault Detection of Environmental Signals with Uncharacterised.pdf},
}

@inproceedings{gunter_sampling_2014,
	title = {Sampling for {Inference} in {Probabilistic} {Models} with {Fast} {Bayesian} {Quadrature}},
	url = {http://arxiv.org/abs/1411.0439},
	abstract = {We propose a novel sampling framework for inference in probabilistic models: an active learning approach that converges more quickly (in wall-clock time) than Markov chain Monte Carlo (MCMC) benchmarks. The central challenge in probabilistic inference is numerical integration, to average over ensembles of models or unknown (hyper-)parameters (for example to compute the marginal likelihood or a partition function). MCMC has provided approaches to numerical integration that deliver state-of-the-art inference, but can suffer from sample inefficiency and poor convergence diagnostics. Bayesian quadrature techniques offer a model-based solution to such problems, but their uptake has been hindered by prohibitive computation costs. We introduce a warped model for probabilistic integrands (likelihoods) that are known to be non-negative, permitting a cheap active learning scheme to optimally select sample locations. Our algorithm is demonstrated to offer faster convergence (in seconds) relative to simple Monte Carlo and annealed importance sampling on both synthetic and real-world examples.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	author = {Gunter, Tom and Osborne, Michael A. and Garnett, Roman and Hennig, Philipp and Roberts, Stephen J.},
	month = nov,
	year = {2014},
	note = {https://github.com/OxfordML/wsabi},
	keywords = {Statistics - Machine Learning},
	file = {5680/Gunter et al_2014_Sampling for Inference in Probabilistic Models with Fast Bayesian Quadrature.pdf},
}

@inproceedings{osborne_gaussian_2009,
	title = {Gaussian processes for global optimization},
	abstract = {We introduce a novel Bayesian approach to global optimization using Gaussian processes. We frame the optimization of both noisy and noiseless functions as sequential decision problems, and introduce myopic and non-myopic solutions to them. Here our solutions can be tailored to exactly the degree of confidence we require of them. The use of Gaussian processes allows us to benefit from the incorporation of prior knowledge about our objective function, and also from any derivative observations. Using this latter fact, we introduce an innovative method to combat conditioning problems. Our algorithm demonstrates a significant improvement over its competitors in overall performance across a wide range of canonical test problems.},
	booktitle = {3rd international conference on learning and intelligent optimization ({LION3})},
	author = {Osborne, Michael A. and Garnett, Roman and Roberts, Stephen J.},
	year = {2009},
	pages = {1--15},
	file = {5928/Osborne et al_2009_Gaussian processes for global optimization.pdf},
}

@inproceedings{garnett_bayesian_2010,
	title = {Bayesian optimization for sensor set selection},
	isbn = {1-60558-988-8},
	doi = {10.1145/1791212.1791238},
	abstract = {We consider the problem of selecting an optimal set of sensors, as determined, for example, by the predictive accuracy of the resulting sensor network. Given an underlying metric between pairs of set elements, we introduce a natural metric between sets of sensors for this task. Using this metric, we can construct covariance functions over sets, and thereby perform Gaussian process inference over a function whose domain is a power set. If the function has additional inputs, our covariances can be readily extended to incorporate them—allowing us to consider, for example, functions over both sets and time. These functions can then be optimized using Gaussian process global optimization (GPGO). We use the root mean squared error (RMSE) of the predictions made using a set of sensors at a particular time as an example of such a function to be optimized; the optimal point specifies the best choice of sensor locations. We demonstrate the resulting method by dynamically selecting the best subset of a given set of weather sensors for the prediction of the air temperature across the United Kingdom.},
	booktitle = {Proceedings of the 9th {ACM}/{IEEE} {International} {Conference} on {Information} {Processing} in {Sensor} {Networks} ({IPSN})},
	publisher = {ACM},
	author = {Garnett, Roman and Osborne, Michael A. and Roberts, Stephen J.},
	year = {2010},
	pages = {209--219},
	file = {5909/Garnett et al_2010_Bayesian optimization for sensor set selection.pdf},
}

@inproceedings{osborne_bayesian_2012,
	title = {Bayesian quadrature for ratios},
	abstract = {We describe a novel approach to quadrature for ratios of probabilistic integrals, such as are used to compute posterior probabilities. This approach offers performance superior to Monte Carlo methods by exploiting a Bayesian quadrature framework. We improve upon previous Bayesian quadrature techniques by explicitly modelling the nonnegativity of our integrands, and the correlations that exist between them. It offers most where the integrand is multi-modal and expensive to evaluate. We demonstrate the efficacy of our method on data from the Kepler space telescope.},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics} ({AISTATS})},
	author = {Osborne, Michael A. and Garnett, Roman and Roberts, Stephen J. and Hart, Christopher and Aigrain, Suzanne and Gibson, Neale},
	year = {2012},
	pages = {832--840},
	file = {5845/Osborne et al_2012_Bayesian quadrature for ratios2.pdf},
}

@inproceedings{fischer_recommending_2013,
	title = {Recommending energy tariffs and load shifting based on smart household usage profiling},
	isbn = {1-4503-1965-3},
	abstract = {We present a system and study of personalized energyrelated recommendation. AgentSwitch utilizes electricity usage data collected from users’ households over a period of time to realize a range of smart energy-related recommendations on energy tariffs, load detection and usage shifting. The web service is driven by a third party real-time energy tariff API (uSwitch), an energy data store, a set of algorithms for usage prediction, and appliance-level load disaggregation. We present the system design and user evaluation consisting of interviews and interface walkthroughs. We recruited participants from a previous study during which three months of their household’s energy use was recorded to evaluate personalized recommendations in AgentSwitch. Our contributions are a) a systems architecture for personalized energy services; and b) findings from the evaluation that reveal challenges in designing energy-related recommender systems. In response to the challenges we formulate design recommendations to mitigate barriers to switching tariffs, to incentivize load shifting, and to automate energy management.},
	booktitle = {Proceedings of the 2013 international conference on {Intelligent} user interfaces ({IUI})},
	publisher = {ACM},
	author = {Fischer, Joel E. and Ramchurn, Sarvapali D. and Osborne, Michael A. and Parson, Oliver and Huynh, Trung Dong and Alam, Muddasser and Pantidi, Nadia and Moran, Stuart and Bachour, Khaled and Reece, Steve},
	year = {2013},
	pages = {383--394},
	file = {5819/Fischer et al_2013_Recommending energy tariffs and load shifting based on smart household usage.pdf},
}

@inproceedings{osborne_towards_2008,
	address = {Washington, DC, USA},
	series = { {IPSN} '08},
	title = {Towards {Real}-{Time} {Information} {Processing} of {Sensor} {Network} {Data} {Using} {Computationally} {Efficient} {Multi}-output {Gaussian} {Processes}},
	isbn = {978-0-7695-3157-1},
	url = {http://dx.doi.org/10.1109/IPSN.2008.25},
	doi = {10.1109/IPSN.2008.25},
	abstract = {In this paper, we describe a novel, computationally efficient algorithm that facilitates the autonomous acquisition of readings from sensor networks (deciding when and which sensor to acquire readings from at any time), and which can, with minimal domain knowledge, perform a range of information processing tasks including modelling the accuracy of the sensor readings, predicting the value of missing sensor readings, and predicting how the monitored environmental variables will evolve into the future. Our motivating scenario is the need to provide situational awareness support to first responders at the scene of a large scale incident, and to this end, we describe a novel iterative formulation of a multi-output Gaussian process that can build and exploit a probabilistic model of the environmental variables being measured (including the correlations and delays that exist between them). We validate our approach using data collected from a network of weather sensors located on the south coast of England.},
	urldate = {2014-08-30},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Information} {Processing} in {Sensor} {Networks} ({IPSN})},
	publisher = {IEEE Computer Society},
	author = {Osborne, Michael A. and Roberts, Stephen J. and Rogers, Alex and Ramchurn, Sarvapali D. and Jennings, Nicholas R.},
	year = {2008},
	keywords = {Gaussian processes, information processing, sensor network},
	pages = {109--120},
	file = {5942/Osborne et al_2008_Towards Real-Time Information Processing of Sensor Network Data Using.pdf},
}

@inproceedings{garnett_sequential_2009,
	title = {Sequential {Bayesian} prediction in the presence of changepoints},
	isbn = {1-60558-516-5},
	abstract = {- ence of changepoints. Unlike previous ap- proaches, which focus on the problem of de- tecting and locating changepoints, our al- gorithm focuses on the problem of making predictions even when such changes might be present. We introduce nonstationary co- variance functions to be used in Gaussian process prediction that model such changes, then proceed to demonstrate how to effec- tively manage the hyperparameters associ- ated with those covariance functions. By us- ing Bayesian quadrature, we can integrate out the hyperparameters, allowing us to cal- culate the marginal predictive distribution. Furthermore, if desired, the posterior distri- bution over putative changepoint locations can be calculated as a natural byproduct of our prediction algorithm.},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning} ({ICML})},
	publisher = {ACM},
	author = {Garnett, Roman and Osborne, Michael A. and Roberts, Stephen J.},
	year = {2009},
	pages = {345--352},
	file = {5933/Garnett et al_2009_Sequential Bayesian prediction in the presence of changepoints.pdf},
}

@inproceedings{ramchurn_agentswitch_2013,
	title = { {AgentSwitch} : towards smart energy tariff selection},
	isbn = {1-4503-1993-9},
	abstract = {In this paper, we present AgentSwitch, a prototype agent-based platform to solve the electricity tariff selection problem. AgentSwitch incorporates novel algorithms to make predictions of hourly energy usage as well as detect (and suggest to the user) deferrable loads that could be shifted to off-peak times to maximise savings. To take advantage of group discounts from energy retailers, we develop a new scalable collective energy purchasing mechanism, based on the Shapley value, that ensures individual members of a collective (interacting through AgentSwitch) fairly share the discounts. To demonstrate the effectiveness of our algorithms we empirically evaluate them individually on real-world data (with up to 3000 homes in the UK) and show that they outperform the state of the art in their domains. Finally, to ensure individual components are accountable in providing recommendations, we provide a novel provenance-tracking service to record the flow of data in the system, and therefore provide users with a means of checking the provenance of suggestions from AgentSwitch and assess their reliability.},
	booktitle = {Proceedings of the 2013 international conference on {Autonomous} agents and multi-agent systems ({AAMAS})},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Ramchurn, Sarvapali D. and Osborne, Michael A. and Parson, Oliver and Rahwan, Talal and Maleki, Sasan and Reece, Steve and Huynh, Trung D. and Alam, Muddasser and Fischer, Joel E. and Rodden, Tom},
	year = {2013},
	pages = {981--988},
	file = {5808/Ramchurn et al_2013_AgentSwitch.pdf},
}

@inproceedings{briol_frank-wolfe_2015,
	title = {Frank-{Wolfe} {Bayesian} {Quadrature}: {Probabilistic} {Integration} with {Theoretical} {Guarantees}},
	shorttitle = {Frank-{Wolfe} {Bayesian} {Quadrature}},
	url = {http://arxiv.org/abs/1506.02681},
	abstract = {There is renewed interest in formulating integration as an inference problem, motivated by obtaining a full distribution over numerical error that can be propagated through subsequent computation. Current methods, such as Bayesian Quadrature, demonstrate impressive empirical performance but lack theoretical analysis. An important challenge is to reconcile these probabilistic integrators with rigorous convergence guarantees. In this paper, we present the first probabilistic integrator that admits such theoretical treatment, called Frank-Wolfe Bayesian Quadrature (FWBQ). Under FWBQ, convergence to the true value of the integral is shown to be exponential and posterior contraction rates are proven to be superexponential. In simulations, FWBQ is competitive with state-of-the-art methods and out-performs alternatives based on Frank-Wolfe optimisation. Our approach is applied to successfully quantify numerical error in the solution to a challenging model choice problem in cellular biology.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	author = {Briol, François-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A.},
	month = jun,
	year = {2015},
	keywords = {Statistics - Machine Learning},
	file = {5567/Briol et al_2015_Frank-Wolfe Bayesian Quadrature.pdf},
}

@inproceedings{osborne_active_2012,
	title = {Active learning of model evidence using {Bayesian} quadrature},
	abstract = {Numerical integration is a key component of many problems in scientific computing, statistical modelling, and machine learning. Bayesian Quadrature is a modelbased method for numerical integration which, relative to standard Monte Carlo methods, offers increased sample efficiency and a more robust estimate of the uncertainty in the estimated integral. We propose a novel Bayesian Quadrature approach for numerical integration when the integrand is non-negative, such as the case of computing the marginal likelihood, predictive distribution, or normalising constant of a probabilistic model. Our approach approximately marginalises the quadrature model’s hyperparameters in closed form, and introduces an active learning scheme to optimally select function evaluations, as opposed to using Monte Carlo samples. We demonstrate our method on both a number of synthetic benchmarks and a real scientific problem from astronomy.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	author = {Osborne, Michael A. and Duvenaud, David K. and Garnett, Roman and Rasmussen, Carl E. and Roberts, Stephen J. and Ghahramani, Zoubin},
	year = {2012},
	pages = {46--54},
	file = {5846/Osborne et al_2012_Active learning of model evidence using Bayesian quadrature.pdf},
}

@inproceedings{fitzsimons_improved_2018,
	title = {Improved stochastic trace estimation using mutually unbiased bases},
	url = {http://arxiv.org/abs/1608.00117},
	abstract = {We examine the problem of estimating the trace of a matrix A when given access to an oracle which computes x† A x for an input vector x. We make use of the basis vectors from a set of mutually unbiased bases, widely studied in the field of quantum information processing, in the selection of probing vectors x. This approach offers a new state of the art single shot sampling variance while requiring only O(log(n)) random bits to generate each vector. This significantly improves on traditional methods such as Hutchinson's and Gaussian estimators in terms of the number of random bits required and worst case sample variance.},
	booktitle = {34th {Conference} on {Uncertainty} in {Artificial} {Intelligence} ({UAI})},
	author = {Fitzsimons, Jack K. and Osborne, Michael A. and Roberts, Stephen J. and Fitzsimons, Joe F.},
	year = {2018},
	file = {5288/Fitzsimons et al_2018_Improved stochastic trace estimation using mutually unbiased bases.pdf},
}

@inproceedings{sarkar_machine_2016,
	title = {A {Machine} {Learning} {Approach} to the {Prediction} of {Tidal} {Currents}.},
	url = {http://users.ox.ac.uk/~spet1235/ISOPE-2016-TPC-0969-final.pdf},
	abstract = {We propose the use of techniques from Machine Learning for the prediction of tidal currents. The classical methodology of harmonic analysis is widely used in the prediction of tidal currents and computer algorithms based on the method have been used for decades for the purpose. The approach determines parameters by minimizing the difference between the raw data and model output using the least squares optimization approach. However, although the approach is considered to be state-of-the-art, it possesses several drawbacks that can lead to significant prediction errors, especially at locations of fast tidal currents and ’noisy’ tidal signal. In general, careful selection of tidal constituents is required in order to achieve good predictions, and the underlying assumption of stationarity in time can restrict the applicability of the method to particular situations. There is a need for principled approaches which can handle uncertainty and accommodate noise in the data. In this work, we use Gaussian process, a Bayesian non-parametric technique, to predict tidal currents. The overall objective is to take advantage of the recent progress in machine learning to construct a robust yet efficient algorithm. The development can specifically benefit the tidal energy community, aiming to harness energy from location of fast tidal currents.},
	booktitle = {The {Proceedings} of {The} {Twenty}-sixth (2016) {International} {Ocean} {And} {Polar} {Engineering} {Conference}},
	author = {Sarkar, Dripta and Osborne, Michael and Adcock, Thomas},
	year = {2016},
	file = {5494/Sarkar et al_2016_A Machine Learning Approach to the Prediction of Tidal Currents.pdf},
}

@inproceedings{gonzalez_glasses:_2016,
	title = { {GLASSES}: {Relieving} {The} {Myopia} {Of} {Bayesian} {Optimisation}},
	shorttitle = { {GLASSES}},
	url = {http://jmlr.org/proceedings/papers/v51/gonzalez16b.html},
	abstract = {We present GLASSES: Global optimisation with Look-Ahead through Stochastic
Simulation and Expected-loss Search. The majority of global optimisation
approaches in use are myopic, in only considering the impact of the next function value; the non-myopic approaches that do exist are able to consider only a handful of future evaluations. Our novel algorithm, GLASSES, permits the consideration of dozens of evaluations into the future.  This is done by approximating the ideal look-ahead loss function, which is expensive to evaluate, by a cheaper alternative in which the future steps of the algorithm are simulated beforehand. An Expectation Propagation algorithm is used to compute the expected value of the loss. We show that the far-horizon planning thus enabled leads to substantive performance gains in empirical tests.},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Artificial} {Intelligence} and {Statistics} ({AISTATS})},
	author = {Gonzalez, Javier and Osborne, Michael A. and Lawrence, Neil},
	year = {2016},
	note = {https://github.com/SheffieldML/GPyOpt/tree/GLASSES},
	pages = {790--799},
	file = {5507/Gonzalez et al_2016_GLASSES.pdf},
}

@inproceedings{cutajar_preconditioning_2016,
	title = {Preconditioning {Kernel} {Matrices}},
	url = {http://arxiv.org/abs/1602.06693},
	abstract = {The computational and storage complexity of kernel machines presents the primary barrier to their scaling to large, modern, datasets. A common way to tackle the scalability issue is to use the conjugate gradient algorithm, which relieves the constraints on both storage (the kernel matrix need not be stored) and computation (both stochastic gradients and parallelization can be used). Even so, conjugate gradient is not without its own issues: the conditioning of kernel matrices is often such that conjugate gradients will have poor convergence in practice. Preconditioning is a common approach to alleviating this issue. Here we propose preconditioned conjugate gradients for kernel machines, and develop a broad range of preconditioners particularly useful for kernel matrices. We describe a scalable approach to both solving kernel machines and learning their hyperparameters. We show this approach is exact in the limit of iterations and outperforms state-of-the-art approximations for a given computational budget.},
	booktitle = {Proceedings of {The} 33rd {International} {Conference} on {Machine} {Learning} ({ICML})},
	author = {Cutajar, Kurt and Osborne, Michael A. and Cunningham, John P. and Filippone, Maurizio},
	month = feb,
	year = {2016},
	note = {https://is.gd/365blF},
	keywords = {Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
	file = {5465/Cutajar et al_2016_Preconditioning Kernel Matrices.pdf},
}

@inproceedings{lloyd_variational_2015,
	title = {Variational {Inference} for {Gaussian} {Process} {Modulated} {Poisson} {Processes}},
	url = {http://jmlr.org/proceedings/papers/v37/lloyd15.html},
	abstract = {We present the first fully variational Bayesian inference scheme for continuous Gaussian-process-modulated Poisson processes. Such point processes are used in a variety of domains, including neuroscience, geo-statistics and astronomy, but their use is hindered by the computational cost of existing inference schemes. Our scheme: requires no discretisation of the domain; scales linearly in the number of observed events; and is many orders of magnitude faster than previous sampling based approaches. The resulting algorithm is shown to outperform standard methods on synthetic examples, coal mining disaster data and in the prediction of Malaria incidences in Kenya.},
	booktitle = {Proceedings of {The} 32nd {International} {Conference} on {Machine} {Learning} ({ICML})},
	author = {Lloyd, Chris and Gunter, Tom and Osborne, Michael A. and Roberts, Stephen},
	year = {2015},
	pages = {1814--1822},
	file = {5627/Lloyd et al_2015_Variational Inference for Gaussian Process Modulated Poisson Processes.pdf},
}

@inproceedings{riar_energy_2016,
	title = {Energy management of a microgrid: {Compensating} for the difference between the real and predicted output power of photovoltaics},
	shorttitle = {Energy management of a microgrid},
	doi = {10.1109/PEDG.2016.7527042},
	abstract = {An increasing awareness of energy efficiency has led to the development of several improved converter topologies, semiconductor devices and control schemes for distributed energy resources, and, particularly, for microgrids. Recent advances in energy management systems (EMS) for microgrids have improved upon existing methods in several aspects, including prediction of power generated by photovoltaics (PV), and optimal management of electrical energy storage. However, the actual generated PV power may deviate from predictions for several reasons, such as rapid cloud changes or system faults. This paper contributes to the ongoing research on EMS control schemes by proposing a model predictive control (MPC) scheme that adapts to the difference between the actual and predicted output power of PV. The key benefit of this approach is its ability to rapidly adapt to varying operating conditions of the PV without increasing the computational burden of a typical MPC scheme. The feasibility of the scheme is demonstrated using simulations of 5 kW microgrid system compromising a 5 kW/400 Ah battery, 10 kW PV and 5 kW grid/load connection. The proposed scheme reduces variations in the state of charge (SOC) of a battery. The proposed scheme also reduces the energy taken from grid and this improvement in performance is a function of the difference between the actual and the predicted power.},
	booktitle = {2016 {IEEE} 7th {International} {Symposium} on {Power} {Electronics} for {Distributed} {Generation} {Systems} ({PEDG})},
	author = {Riar, Baljit and Lee, Jaehwa and Tosi, Alessandra and Duncan, Stephen and Osborne, Michael A. and Howey, David},
	month = jun,
	year = {2016},
	keywords = {Batteries, Battery storage system, EMS control schemes, Energy management, MPC scheme, Microgrids, Model predictive control, Optimisation, Optimization, PV, Power generation, Predictive control, State of charge, battery, battery state of charge variations reduction, computational burden, converter topology, distributed energy resource, distributed power generation, electrical energy storage optimal management, energy conservation, energy efficiency awareness, energy management system, energy management systems, energy storage, grid-load connection, microgrid, microgrid energy management system, model predictive control scheme, photovoltaic (PV) system, photovoltaic power systems, photovoltaics, power 10 kW, power 5 kW, power convertors, power generation control, power generation prediction, power grids, secondary cells, semiconductor device},
	pages = {1--7},
	file = {5440/Riar et al_2016_Energy management of a microgrid.pdf},
}

@inproceedings{rainforth_bayesian_2016,
	title = {Bayesian {Optimization} for {Probabilistic} {Programs}},
	url = {http://papers.nips.cc/paper/6421-bayesian-optimization-for-probabilistic-programs.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	publisher = {Curran Associates, Inc.},
	author = {Rainforth, Tom and Le, Tuan Anh and van de Meent, Jan-Willem and Osborne, Michael A and Wood, Frank},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	note = {https://github.com/probprog/bopp},
	pages = {280--288},
	file = {5495/Rainforth et al_2016_Bayesian Optimization for Probabilistic Programs.pdf},
}

@inproceedings{fruehwirt_bayesian_2017,
	title = {Bayesian {Gaussian} {Process} {Classification} from {Event}-{Related} {Brain} {Potentials} in {Alzheimer}’s {Disease}},
	volume = {10259},
	url = {https://is.gd/z5lLxE},
	abstract = {Event-related potentials (ERPs) have been shown to reflect neurodegenerative processes in Alzheimer’s disease (AD) and might qualify as non-invasive and cost-effective markers to facilitate the objectivization of AD assessment in daily clinical practice. Lately, the combination of multivariate pattern analysis (MVPA) and Gaussian process classification (GPC) has gained interest in the neuroscientific community. Here, we demonstrate how a MVPA-GPC approach can be applied to electrophysiological data. Furthermore, in order to account for the temporal information of ERPs, we develop a novel method that integrates interregional synchrony of ERP time signatures. By using real-life ERP recordings of a prospective AD cohort study (PRODEM), we empirically investigate the usefulness of the proposed framework to build neurophysiological markers for single subject classification tasks. GPC outperforms the probabilistic reference method in both tasks, with the highest AUC overall (0.802) being achieved using the new spatiotemporal method in the prediction of rapid cognitive decline.},
	booktitle = {Artificial {Intelligence} in {Medicine}: 16th {Conference} on {Artificial} {Intelligence} in {Medicine}, {AIME} 2017, {Vienna}, {Austria}, {June} 21-24, 2017, {Proceedings}},
	publisher = {Springer},
	author = {Fruehwirt, Wolfgang and Zhang, Pengfei and Gerstgrasser, Matthias and Grossegger, Dieter and Schmidt, Reinhold and Benke, Thomas and Dal-Bianco, Peter and Ransmayr, Gerhard and Weydemann, Leonard and Garn, Heinrich and Waser, Markus and Osborne, Michael A and Dorffner, Georg},
	year = {2017},
	pages = {65},
	file = {5400/Fruehwirt et al_2017_Bayesian Gaussian Process Classification from Event-Related Brain Potentials in.pdf},
}

@inproceedings{fitzsimons_entropic_2017,
	title = {Entropic {Trace} {Estimates} for {Log} {Determinants}},
	url = {https://arxiv.org/abs/1704.07223},
	abstract = {The scalable calculation of matrix determinants has been a bottleneck to the widespread application of many machine learning methods such as determinantal point processes, Gaussian processes, generalised Markov random  elds, graph models and many others. In this work, we estimate log determinants under the framework of maximum entropy, given information in the form of moment constraints from stochastic trace estimation. The estimates demonstrate a signi cant improvement on state-of-the-art alternative methods, as shown on a wide variety of matrices from the SparseSuite Matrix Collection. By taking the example of a general Markov random  eld, we also demonstrate how this approach can signifcantly accelerate inference in large-scale learning methods involving the log determinant.},
	urldate = {2017-06-21},
	booktitle = { {ECML}/{PKDD} 2017, {European} {Conference} on {Machine} {Learning} and {Principles} and {Practice} of {Knowledge} {Discovery} in {Databases}, {September} 18-22, 2017, {Skopje}, {Macedonia}},
	author = {Fitzsimons, Jack and Granziol, Diego and Cutajar, Kurt and Osborne, Michael and Filippone, Maurizio and Roberts, Stephen},
	year = {2017},
	file = {5402/Fitzsimons et al_2017_Entropic Trace Estimates for Log Determinants.pdf},
}

@inproceedings{fitzsimons_bayesian_2017,
	title = {Bayesian {Inference} of {Log} {Determinants}},
	url = {https://arxiv.org/abs/1704.01445},
	abstract = {The log-determinant of a kernel matrix appears in a variety of machine learning problems, ranging from determinantal point processes and generalized Markov random fields, through to the training of Gaussian processes. Exact calculation of this term is often intractable when the size of the kernel matrix exceeds a few thousand. In the spirit of probabilistic numerics, we reinterpret the problem of computing the log-determinant as a Bayesian inference problem. In particular, we combine prior knowledge in the form of bounds from matrix theory and evidence derived from stochastic trace estimation to obtain probabilistic estimates for the log-determinant and its associated uncertainty within a given computational budget. Beyond its novelty and theoretic appeal, the performance of our proposal is competitive with state-of-the-art approaches to approximating the log-determinant, while also quantifying the uncertainty due to budget-constrained evidence.},
	urldate = {2017-06-21},
	booktitle = {Uncertainty in {Artificial} {Intelligence} ({UAI})},
	author = {Fitzsimons, Jack and Cutajar, Kurt and Osborne, Michael and Roberts, Stephen and Filippone, Maurizio},
	year = {2017},
	file = {5403/Fitzsimons et al_2017_Bayesian Inference of Log Determinants.pdf},
}

@inproceedings{bewsher_distribution_2017,
	title = {Distribution of {Gaussian} {Process} {Arc} {Lengths}},
	url = {http://proceedings.mlr.press/v54/bewsher17a.html},
	abstract = {We present the first treatment of the arc length of the Gaussian Process (gp) with more than a single output dimension. Gps are commonly used for tasks such as trajectory modelling, where path length is a crucial quantity of interest. Previously, only paths in one dimension have been considered, with no theoretical consideration of higher dimensional problems. We fill the gap in the existing literature by deriving the moments of the arc length for a stationary gp with multiple output dimensions. A new method is used to derive the mean of a one-dimensional gp over a finite interval, by considering the distribution of the arc length integrand. This technique is used to derive an approximate distribution over the arc length of a vector valued gp in Rn by moment matching the distribution. Numerical simulations confirm our theoretical derivations.},
	language = {en},
	urldate = {2017-06-21},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Artificial} {Intelligence} and {Statistics} ({AISTATS})},
	author = {Bewsher, Justin and Tosi, Alessandra and Osborne, Michael and Roberts, Stephen},
	month = apr,
	year = {2017},
	file = {5354/Bewsher et al_2017_Distribution of Gaussian Process Arc Lengths.pdf},
}

@inproceedings{paul_alternating_2018,
	title = {Alternating {Optimisation} and {Quadrature} for {Robust} {Control}},
	url = {http://www.cs.ox.ac.uk/people/shimon.whiteson/pubs/paulaaai18.pdf},
	abstract = {Bayesian optimisation has been successfully applied to a variety of reinforcement learning problems. However, the traditional approach for learning optimal policies in simulators does not utilise the opportunity to improve learning by adjusting certain environment variables: state features that are unobservable and randomly determined by the environment in a physical setting but are controllable in a simulator. This paper considers the problem of finding a robust policy while taking into account the impact of environment variables. We present Alternating Optimisation and Quadrature (ALOQ), which uses Bayesian optimisation and Bayesian quadrature to address such settings. ALOQ is robust to the presence of significant rare events, which may not be observable under random sampling, but play a substantial role in determining the optimal policy. Experimental results across different domains show that ALOQ can learn more efficiently and robustly than existing methods.},
	urldate = {2017-12-21},
	booktitle = {Proceedings of the {Thirty}-{Second} {AAAI} {Conference} on {Artificial} {Intelligence} ({AAAI})},
	author = {Paul, Supratik and Chatzilygeroudis, Konstantinos and Ciosek, Kamil and Mouret, Jean-Baptiste and Osborne, Michael A. and Whiteson, Shimon},
	year = {2018},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning, Statistics - Machine Learning},
	file = {5285/Paul et al_2018_Alternating Optimisation and Quadrature for Robust Control.pdf},
}

@inproceedings{abbati_adageo_2018,
	title = { {AdaGeo} : {Adaptive} {Geometric} {Learning} for {Optimization} and {Sampling}},
	shorttitle = { {AdaGeo}},
	url = {http://proceedings.mlr.press/v84/abbati18a.html},
	abstract = {Gradient-based optimization and Markov Chain Monte Carlo sampling can be found at the heart of several machine learning methods. In high-dimensional settings, well-known issues such as slow-mixing,...},
	language = {en},
	urldate = {2018-04-13},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics} ({AISTATS})},
	author = {Abbati, Gabriele and Tosi, Alessandra and Osborne, Michael and Flaxman, Seth},
	month = mar,
	year = {2018},
	pages = {226--234},
	file = {5240/Abbati et al_2018_AdaGeo.pdf},
}

@inproceedings{richardson_battery_2017,
	title = {Battery {Capacity} {Estimation} {From} {Partial}-{Charging} {Data} {Using} {Gaussian} {Process} {Regression}},
	url = {http://dx.doi.org/10.1115/DSCC2017-5365},
	doi = {10.1115/DSCC2017-5365},
	abstract = {Accurate on-board capacity estimation is of critical importance in lithium-ion battery applications. Battery charging/discharging often occurs under a constant current load, and hence voltage vs. time measurements under this condition may be accessible in practice. This paper presents a novel diagnostic technique, Gaussian Process regression for In-situ Capacity Estimation (GP-ICE), which is capable of estimating the battery capacity using voltage vs. time measurements over short periods of galvanostatic operation.The approach uses Gaussian process regression to map from voltage values at a selection of uniformly distributed times, to cell capacity. Unlike previous works, GP-ICE does not rely on interpreting the voltage-time data through the lens of Incremental Capacity (IC) or Differential Voltage (DV) analysis. This overcomes both the need to differentiate the voltage-time data (a process which amplifies measurement noise), and the requirement that the range of voltage measurements encompasses the peaks in the IC/DV curves. Rather, GP-ICE gives insight into which portions of the voltage range are most informative about the capacity for a particular cell. We apply GP-ICE to a dataset of 8 cells, which were aged by repeated application of an ARTEMIS urban drive cycle. Within certain voltage ranges, as little as 10 seconds of charge data is sufficient to enable capacity estimates with ∼ 2\% RMSE.},
	urldate = {2018-04-16},
	booktitle = { {ASME} 2017 {Dynamic} {Systems} and {Control} {Conference}},
	author = {Richardson, Robert R. and Birkl, Christoph R. and Osborne, Michael A. and Howey, David A.},
	month = oct,
	year = {2017},
	file = {5301/Richardson et al_2017_Battery Capacity Estimation From Partial-Charging Data Using Gaussian Process.pdf},
}

@inproceedings{mcleod_optimization_2018,
	title = {Optimization, fast and slow: optimally switching between local and {Bayesian} optimization},
	shorttitle = {Optimization, fast and slow},
	url = {http://arxiv.org/abs/1805.08610},
	abstract = {We develop the first Bayesian Optimization algorithm, BLOSSOM, which selects between multiple alternative acquisition functions and traditional local optimization at each step. This is combined with a novel stopping condition based on expected regret. This pairing allows us to obtain the best characteristics of both local and Bayesian optimization, making efficient use of function evaluations while yielding superior convergence to the global minimum on a selection of optimization problems, and also halting optimization once a principled and intuitive stopping condition has been fulfilled.},
	urldate = {2018-05-23},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning} ({ICML})},
	author = {McLeod, Mark and Osborne, Michael A. and Roberts, Stephen J.},
	month = may,
	year = {2018},
	note = {https://github.com/markm541374/gpbo},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	file = {5225/McLeod et al_2018_Optimization, fast and slow.pdf},
}

@inproceedings{ru_fast_2018,
	title = {Fast {Information}-theoretic {Bayesian} {Optimisation}},
	url = {http://arxiv.org/abs/1711.00673},
	abstract = {Information-theoretic Bayesian optimisation techniques have demonstrated state-of-the-art performance in tackling important global optimisation problems. However, current information-theoretic approaches require many approximations in implementation, introduce often-prohibitive computational overhead and limit the choice of kernels available to model the objective. We develop a fast information-theoretic Bayesian Optimisation method, FITBO, that avoids the need for sampling the global minimiser, thus significantly reducing computational overhead. Moreover, in comparison with existing approaches, our method faces fewer constraints on kernel choice and enjoys the merits of dealing with the output space. We demonstrate empirically that FITBO inherits the performance associated with information-theoretic Bayesian optimisation, while being even faster than simpler Bayesian optimisation approaches, such as Expected Improvement.},
	urldate = {2018-06-07},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning} ({ICML})},
	author = {Ru, Binxin and McLeod, Mark and Granziol, Diego and Osborne, Michael A.},
	year = {2018},
	note = {https://github.com/rubinxin/FITBO},
	keywords = {Statistics - Machine Learning},
	file = {5283/Ru et al_2018_Fast Information-theoretic Bayesian Optimisation.pdf},
}

@inproceedings{abbati_ares_2019,
	title = { {AReS} and {MaRS} {Adversarial} and {MMD}-{Minimizing} {Regression} for {SDEs}},
	url = {http://proceedings.mlr.press/v97/abbati19a.html},
	abstract = {Stochastic differential equations are an important modeling class in many disciplines. Consequently, there exist many methods relying on various discretization and numerical integration schemes. In...},
	language = {en},
	urldate = {2019-09-29},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	author = {Abbati, Gabriele and Wenk, Philippe and Osborne, Michael A. and Krause, Andreas and Schölkopf, Bernhard and Bauer, Stefan},
	month = may,
	year = {2019},
	note = {https://github.com/gabb7/AReS-MaRS},
	pages = {1--10},
	file = {5144/Abbati et al_2019_AReS and MaRS Adversarial and MMD-Minimizing Regression for SDEs.pdf},
}

@inproceedings{alvi_asynchronous_2019,
	title = {Asynchronous {Batch} {Bayesian} {Optimisation} with {Improved} {Local} {Penalisation}},
	url = {http://proceedings.mlr.press/v97/alvi19a.html},
	abstract = {Batch Bayesian optimisation (BO) has been successfully applied to hyperparameter tuning using parallel computing, but it is wasteful of resources: workers that complete jobs ahead of others are lef...},
	language = {en},
	urldate = {2019-09-29},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	author = {Alvi, Ahsan and Ru, Binxin and Calliess, Jan-Peter and Roberts, Stephen and Osborne, Michael A.},
	month = may,
	year = {2019},
	note = {https://github.com/a5a/asynchronous-BO},
	pages = {253--262},
	file = {5143/Alvi et al_2019_Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation.pdf},
}

@inproceedings{chai_automated_2019,
	title = {Automated {Model} {Selection} with {Bayesian} {Quadrature}},
	url = {http://proceedings.mlr.press/v97/chai19a.html},
	abstract = {We present a novel technique for tailoring Bayesian quadrature (BQ) to model selection. The state-of-the-art for comparing the evidence of multiple models relies on Monte Carlo methods, which conve...},
	language = {en},
	urldate = {2019-09-29},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	author = {Chai, Henry and Ton, Jean-Francois and Osborne, Michael A. and Garnett, Roman},
	month = may,
	year = {2019},
	pages = {931--940},
	file = {5142/Chai et al_2019_Automated Model Selection with Bayesian Quadrature.pdf},
}

@inproceedings{paul_fingerprint_2019,
	title = {Fingerprint {Policy} {Optimisation} for {Robust} {Reinforcement} {Learning}},
	url = {http://proceedings.mlr.press/v97/paul19a.html},
	abstract = {Policy gradient methods ignore the potential value of adjusting environment variables: unobservable state features that are randomly determined by the environment in a physical setting, but are con...},
	language = {en},
	urldate = {2019-09-29},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	author = {Paul, Supratik and Osborne, Michael A. and Whiteson, Shimon},
	month = may,
	year = {2019},
	pages = {5082--5091},
	file = {5140/Paul et al_2019_Fingerprint Policy Optimisation for Robust Reinforcement Learning.pdf},
}

@inproceedings{wagstaff_limitations_2019,
	title = {On the {Limitations} of {Representing} {Functions} on {Sets}},
	url = {http://proceedings.mlr.press/v97/wagstaff19a.html},
	abstract = {Recent work on the representation of functions on sets has considered the use of summation in a latent space to enforce permutation invariance. In particular, it has been conjectured that the dimen...},
	language = {en},
	urldate = {2019-09-29},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	author = {Wagstaff, Edward and Fuchs, Fabian and Engelcke, Martin and Posner, Ingmar and Osborne, Michael A.},
	month = may,
	year = {2019},
	pages = {6487--6494},
	file = {5139/Wagstaff et al_2019_On the Limitations of Representing Functions on Sets.pdf},
}

@inproceedings{duckworth_inferring_2019,
	address = {Honolulu, HI, USA},
	series = { {AIES} '19},
	title = {Inferring {Work} {Task} {Automatability} from {AI} {Expert} {Evidence}},
	isbn = {978-1-4503-6324-2},
	url = {https://doi.org/10.1145/3306618.3314247},
	doi = {10.1145/3306618.3314247},
	abstract = {Despite growing alarm about machine learning technologies automating jobs, there is little good evidence on what activities can be automated using such technologies. We contribute the first dataset of its kind by surveying over 150 top academics and industry experts in machine learning, robotics and AI, receiving over 4,500 ratings of how automatable specific tasks are today. We present a probabilistic machine learning model to learn the patterns connecting expert estimates of task automatability and the skills, knowledge and abilities required to perform those tasks. Our model infers the automatability of over 2,000 work activities, and we show how automation differs across types of activities and types of occupations. Sensitivity analysis identifies the specific skills, knowledge and abilities of activities that drive higher or lower automatability. We provide quantitative evidence of what is perceived to be automatable using the state-of-the-art in machine learning technology. We consider the societal impacts of these results and of task-level approaches.},
	urldate = {2020-01-24},
	booktitle = {Proceedings of the 2019 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {Association for Computing Machinery},
	author = {Duckworth, Paul and Graham, Logan and Osborne, Michael},
	month = jan,
	year = {2019},
	note = {https://drive.google.com/drive/folders/1gvS9fQ2gG9y5VrPyvRWKCh0yxdsqI9V2},
	keywords = {automation, bayesian machine learning, interpretable machine learning, labor economics, open datasets},
	pages = {485--491},
	file = {5172/Duckworth et al_2019_Inferring Work Task Automatability from AI Expert Evidence.pdf},
}

@inproceedings{farquhar_radial_2020,
	title = {Radial {Bayesian} {Neural} {Networks}: {Beyond} {Discrete} {Support} {In} {Large}-{Scale} {Bayesian} {Deep} {Learning}},
	shorttitle = {Radial {Bayesian} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1907.00865},
	abstract = {We propose Radial Bayesian Neural Networks (BNNs): a variational approximate posterior for BNNs which scales well to large models while maintaining a distribution over weight-space with full support. Other scalable Bayesian deep learning methods, like MC dropout or deep ensembles, have discrete support-they assign zero probability to almost all of the weight-space. Unlike these discrete support methods, Radial BNNs' full support makes them suitable for use as a prior for sequential inference. In addition, they solve the conceptual challenges with the a priori implausibility of weight distributions with discrete support. The Radial BNN is motivated by avoiding a sampling problem in 'mean-field' variational inference (MFVI) caused by the so-called 'soap-bubble' pathology of multivariate Gaussians. We show that, unlike MFVI, Radial BNNs are robust to hyperparameters and can be efficiently applied to a challenging real-world medical application without needing ad-hoc tweaks and intensive tuning. In fact, in this setting Radial BNNs out-perform discrete-support methods like MC dropout. Lastly, by using Radial BNNs as a theoretically principled, robust alternative to MFVI we make significant strides in a Bayesian continual learning evaluation.},
	urldate = {2020-05-16},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics} ({AISTATS})},
	author = {Farquhar, Sebastian and Osborne, Michael and Gal, Yarin},
	year = {2020},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {5114/Farquhar et al_2020_Radial Bayesian Neural Networks.pdf},
}

@inproceedings{nguyen_optimal_2021,
	title = {Optimal {Transport} {Kernels} for {Sequential} and {Parallel} {Neural} {Architecture} {Search}},
	url = {http://proceedings.mlr.press/v139/nguyen21d.html},
	abstract = {Neural architecture search (NAS) automates the design of deep neural networks. One of the main challenges in searching complex and non-continuous architectures is to compare the similarity of networks that the conventional Euclidean metric may fail to capture. Optimal transport (OT) is resilient to such complex structure by considering the minimal cost for transporting a network into another. However, the OT is generally not negative definite which may limit its ability to build the positive-definite kernels required in many kernel-dependent frameworks. Building upon tree-Wasserstein (TW), which is a negative definite variant of OT, we develop a novel discrepancy for neural architectures, and demonstrate it within a Gaussian process surrogate model for the sequential NAS settings. Furthermore, we derive a novel parallel NAS, using quality k-determinantal point process on the GP posterior, to select diverse and high-performing architectures from a discrete set of candidates. Empirically, we demonstrate that our TW-based approaches outperform other baselines in both sequential and parallel NAS.},
	language = {en},
	urldate = {2021-08-11},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	publisher = {PMLR},
	author = {Nguyen, Vu and Le, Tam and Yamada, Makoto and Osborne, Michael A.},
	month = jul,
	year = {2021},
	note = {https://github.com/ntienvu/TW\_NAS},
	pages = {8084--8095},
	file = {6549/Nguyen et al_2021_Optimal Transport Kernels for Sequential and Parallel Neural Architecture Search.pdf},
}

@inproceedings{wan_think_2021,
	title = {Think {Global} and {Act} {Local}: {Bayesian} {Optimisation} over {High}-{Dimensional} {Categorical} and {Mixed} {Search} {Spaces}},
	shorttitle = {Think {Global} and {Act} {Local}},
	url = {http://arxiv.org/abs/2102.07188},
	abstract = {High-dimensional black-box optimisation remains an important yet notoriously challenging problem. Despite the success of Bayesian optimisation methods on continuous domains, domains that are categorical, or that mix continuous and categorical variables, remain challenging. We propose a novel solution -- we combine local optimisation with a tailored kernel design, effectively handling high-dimensional categorical and mixed search spaces, whilst retaining sample efficiency. We further derive convergence guarantee for the proposed approach. Finally, we demonstrate empirically that our method outperforms the current baselines on a variety of synthetic and real-world tasks in terms of performance, computational costs, or both.},
	urldate = {2021-08-11},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	author = {Wan, Xingchen and Nguyen, Vu and Ha, Huong and Ru, Binxin and Lu, Cong and Osborne, Michael A.},
	month = jun,
	year = {2021},
	note = {https://github.com/xingchenwan/Casmopolitan},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {6580/Wan et al_2021_Think Global and Act Local.pdf},
}

@inproceedings{ru_bayesian_2020,
	title = {Bayesian {Optimisation} over {Multiple} {Continuous} and {Categorical} {Inputs}},
	url = {http://proceedings.mlr.press/v119/ru20a.html},
	abstract = {Efficient optimisation of black-box problems that comprise both continuous and categorical inputs is important, yet poses significant challenges. We propose a new approach, Continuous and Categorical Bayesian Optimisation (CoCaBO), which combines the strengths of multi-armed bandits and Bayesian optimisation to select values for both categorical and continuous inputs. We model this mixed-type space using a Gaussian Process kernel, designed to allow sharing of information across multiple categorical variables, each with multiple possible values; this allows CoCaBO to leverage all available data efficiently. We extend our method to the batch setting and propose an efficient selection procedure that dynamically balances exploration and exploitation whilst encouraging batch diversity. We demonstrate empirically that our method outperforms existing approaches on both synthetic and real-world optimisation tasks with continuous and categorical inputs.},
	language = {en},
	urldate = {2021-08-11},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	publisher = {PMLR},
	author = {Ru, Binxin and Alvi, Ahsan and Nguyen, Vu and Osborne, Michael A. and Roberts, Stephen},
	month = nov,
	year = {2020},
	note = {https://github.com/rubinxin/CoCaBO\_code},
	pages = {8276--8285},
	file = {6591/Ru et al_2020_Bayesian Optimisation over Multiple Continuous and Categorical Inputs.pdf},
}

@inproceedings{nguyen_knowing_2020,
	title = {Knowing {The} {What} {But} {Not} {The} {Where} in {Bayesian} {Optimization}},
	url = {http://proceedings.mlr.press/v119/nguyen20d.html},
	abstract = {Bayesian optimization has demonstrated impressive success in finding the optimum location x* and value f*=f(x*)=max f(x) of the black-box function f. In some applications, however, the optimum value is known in advance and the goal is to find the corresponding optimum location. Existing work in Bayesian optimization (BO) has not effectively exploited the knowledge of f* for optimization. In this paper, we consider a new setting in BO in which the knowledge of the optimum value is available. Our goal is to exploit the knowledge about f* to search for the location x* efficiently. To achieve this goal, we first transform the Gaussian process surrogate using the information about the optimum value. Then, we propose two acquisition functions, called confidence bound minimization and expected regret minimization, which exploit the knowledge about the optimum value to identify the optimum location efficiently. We show that our approaches work both intuitively and quantitatively achieve better performance against standard BO methods. We demonstrate real applications in tuning a deep reinforcement learning algorithm on the CartPole problem and XGBoost on Skin Segmentation dataset in which the optimum values are publicly available.},
	language = {en},
	urldate = {2021-08-11},
	booktitle = {International {Conference} on {Machine} {Learning} ({ICML})},
	publisher = {PMLR},
	author = {Nguyen, Vu and Osborne, Michael A.},
	month = nov,
	year = {2020},
	note = {https://github.com/ntienvu/KnownOptimum\_BO},
	pages = {7317--7326},
	file = {6595/Nguyen_Osborne_2020_Knowing The What But Not The Where in Bayesian Optimization.pdf},
}

@inproceedings{nguyen_gaussian_2020,
	title = {Gaussian {Process} {Bandit} {Optimization} of the {Thermodynamic} {Variational} {Objective}},
	url = {http://arxiv.org/abs/2010.15750},
	abstract = {Achieving the full promise of the Thermodynamic Variational Objective (TVO), a recently proposed variational lower bound on the log evidence involving a one-dimensional Riemann integral approximation, requires choosing a "schedule" of sorted discretization points. This paper introduces a bespoke Gaussian process bandit optimization method for automatically choosing these points. Our approach not only automates their one-time selection, but also dynamically adapts their positions over the course of optimization, leading to improved model learning and inference. We provide theoretical guarantees that our bandit optimization converges to the regret-minimizing choice of integration points. Empirical validation of our algorithm is provided in terms of improved learning and inference in Variational Autoencoders and Sigmoid Belief Networks.},
	urldate = {2021-08-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	author = {Nguyen, Vu and Masrani, Vaden and Brekelmans, Rob and Osborne, Michael A. and Wood, Frank},
	month = nov,
	year = {2020},
	note = {https://github.com/ntienvu/tvo\_gp\_bandit},
	keywords = {Computer Science - Machine Learning},
	file = {6600/Nguyen et al_2020_Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective.pdf},
}

@inproceedings{ru_interpretable_2021,
	title = {Interpretable {Neural} {Architecture} {Search} via {Bayesian} {Optimisation} with {Weisfeiler}-{Lehman} {Kernels}},
	url = {http://arxiv.org/abs/2006.07556},
	abstract = {Current neural architecture search (NAS) strategies focus only on finding a single, good, architecture. They offer little insight into why a specific network is performing well, or how we should modify the architecture if we want further improvements. We propose a Bayesian optimisation (BO) approach for NAS that combines the Weisfeiler-Lehman graph kernel with a Gaussian process surrogate. Our method optimises the architecture in a highly data-efficient manner: it is capable of capturing the topological structures of the architectures and is scalable to large graphs, thus making the high-dimensional and graph-like search spaces amenable to BO. More importantly, our method affords interpretability by discovering useful network features and their corresponding impact on the network performance. Indeed, we demonstrate empirically that our surrogate model is capable of identifying useful motifs which can guide the generation of new architectures. We finally show that our method outperforms existing NAS approaches to achieve the state of the art on both closed- and open-domain search spaces.},
	urldate = {2021-08-11},
	booktitle = {International {Conference} on {Learning} {Representations} ({ICLR})},
	author = {Ru, Binxin and Wan, Xingchen and Dong, Xiaowen and Osborne, Michael},
	month = feb,
	year = {2021},
	note = {https://github.com/xingchenwan/nasbowl},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {6613/Ru et al_2021_Interpretable Neural Architecture Search via Bayesian Optimisation with.pdf},
}

@inproceedings{nguyen_bayesian_2020,
	title = {Bayesian {Optimization} for {Iterative} {Learning}},
	url = {http://arxiv.org/abs/1909.09593},
	abstract = {The performance of deep (reinforcement) learning systems crucially depends on the choice of hyperparameters. Their tuning is notoriously expensive, typically requiring an iterative training process to run for numerous steps to convergence. Traditional tuning algorithms only consider the final performance of hyperparameters acquired after many expensive iterations and ignore intermediate information from earlier training steps. In this paper, we present a Bayesian optimization (BO) approach which exploits the iterative structure of learning algorithms for efficient hyperparameter tuning. We propose to learn an evaluation function compressing learning progress at any stage of the training process into a single numeric score according to both training success and stability. Our BO framework is then balancing the benefit of assessing a hyperparameter setting over additional training steps against their computation cost. We further increase model efficiency by selectively including scores from different training steps for any evaluated hyperparameter set. We demonstrate the efficiency of our algorithm by tuning hyperparameters for the training of deep reinforcement learning agents and convolutional neural networks. Our algorithm outperforms all existing baselines in identifying optimal hyperparameters in minimal time.},
	urldate = {2021-08-11},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	author = {Nguyen, Vu and Schulze, Sebastian and Osborne, Michael A.},
	year = {2020},
	note = {https://github.com/ntienvu/KnownOptimum\_BO},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {6618/Nguyen et al_2021_Bayesian Optimization for Iterative Learning.pdf},
}

@article{nickson_blitzkriging_2015,
	title = {Blitzkriging : {Kronecker}-structured {Stochastic} {Gaussian} {Processes}},
	shorttitle = {Blitzkriging},
	url = {http://arxiv.org/abs/1510.07965},
	abstract = {We present Blitzkriging, a new approach to fast inference for Gaussian processes, applicable to regression, optimisation and classification. State-of-the-art (stochastic) inference for Gaussian processes on very large datasets scales cubically in the number of 'inducing inputs', variables introduced to factorise the model. Blitzkriging shares state-of-the-art scaling with data, but reduces the scaling in the number of inducing points to approximately linear. Further, in contrast to other methods, Blitzkriging: does not force the data to conform to any particular structure (including grid-like); reduces reliance on error-prone optimisation of inducing point locations; and is able to learn rich (covariance) structure from the data. We demonstrate the benefits of our approach on real data in regression, time-series prediction and signal-interpolation experiments.},
	journal = {arXiv:1510.07965 [stat]},
	author = {Nickson, Thomas and Gunter, Tom and Lloyd, Chris and Osborne, Michael A. and Roberts, Stephen},
	month = oct,
	year = {2015},
	keywords = {preprint},
	file = {5539/Nickson et al_2015_Blitzkriging.pdf},
}

@techreport{reece_anomaly_2009,
	title = {Anomaly detection and removal using nonstationary {Gaussian} processes},
	abstract = {This paper proposes a novel Gaussian process approach to
fault removal in time-series data. Fault removal does not delete
the faulty signal data but, instead, massages the fault from
the data. We assume that only one fault occurs at any one
time and model the signal by two separate non-parametric
Gaussian process models for both the physical phenomenon
and the fault. In order to facilitate fault removal we introduce
the Markov Region Link kernel for handling non-stationary
Gaussian Processes. This kernel is piece-wise stationary but
guarantees that functions generated by it and their derivatives
(when required) are everywhere continuous. We apply this
kernel to the removal of drift and bias errors in faulty sensor
data and also to the recovery of EOG artifact corrupted EEG
signals.},
	institution = {Department of Engineering Science, University of Oxford},
	author = {Reece, Steve and Garnett, Roman and Osborne, Michael A. and Roberts, Stephen J.},
	year = {2009},
	keywords = {preprint},
	file = {5927/Reece et al_2009_Anomaly detection and removal using nonstationary Gaussian processes.pdf},
}

@article{gillani_communication_2014,
	title = {Communication {Communities} in {MOOCs}},
	abstract = {Massive Open Online Courses (MOOCs) bring together thousands of people from different geographies and demographic backgrounds -- but to date, little is known about how they learn or communicate. We introduce a new content-analysed MOOC dataset and use Bayesian Non-negative Matrix Factorization (BNMF) to extract communities of learners based on the nature of their online forum posts. We see that BNMF yields a superior probabilistic generative model for online discussions when compared to other models, and that the communities it learns are differentiated by their composite students' demographic and course performance indicators. These findings suggest that computationally efficient probabilistic generative modelling of MOOCs can reveal important insights for educational researchers and practitioners and help to develop more intelligent and responsive online learning environments.},
	journal = {arXiv preprint arXiv:1403.4640},
	author = {Gillani, Nabeel and Eynon, Rebecca and Osborne, Michael A. and Hjorth, Isis and Roberts, Stephen},
	year = {2014},
	keywords = {preprint},
	file = {5763/Gillani et al_2014_Communication Communities in MOOCs.pdf},
}

@misc{osborne_epistemic_2008,
	title = {Epistemic {Uncertainty} in {Quantum} {Mechanics}},
	author = {Osborne, Michael A.},
	month = apr,
	year = {2008},
	keywords = {preprint},
	file = {5939/Osborne_2008_Epistemic Uncertainty in Quantum Mechanics.pdf},
}

@article{hutter_kernel_2013,
	title = {A {Kernel} for {Hierarchical} {Parameter} {Spaces}},
	url = {http://arxiv.org/abs/1310.5738},
	abstract = {We define a family of kernels for mixed continuous/discrete hierarchical parameter spaces and show that they are positive definite.},
	journal = {arXiv preprint arXiv:1310.5738},
	author = {Hutter, Frank and Osborne, Michael A.},
	year = {2013},
	keywords = {preprint},
	file = {5813/Hutter_Osborne_2013_A Kernel for Hierarchical Parameter Spaces.pdf},
}

@techreport{osborne_gaussian_2007,
	title = {Gaussian processes for prediction},
	abstract = {We propose a powerful prediction algorithm built upon Gaussian processes (GPs). They are
particularly useful for their flexibility, facilitating accurate prediction even in the absence of strong
physical models.
GPs further allow us to work within a complete Bayesian probabilistic framework. As such, we
show how the hyperparameters of our system can be marginalised by use of Bayesian Monte Carlo, a
principled method of approximate integration. We employ the error bars of our GP’s predictions as
a means to select only the most informative data to store. This allows us to introduce an iterative
formulation of the GP to give a dynamic, on-line algorithm. We also show how our error bars can be
used to perform active data selection, allowing the GP to select where and when it should next take a
measurement.
We demonstrate how our methods can be applied to multi-sensor prediction problems where data
may be missing, delayed and/or correlated. In particular, we present a real network of weather sensors
as a testbed for our algorithm.},
	number = {PARG-07-01},
	institution = {Department of Engineering Science, University of Oxford},
	author = {Osborne, Michael A. and Roberts, Stephen J.},
	year = {2007},
	keywords = {preprint},
	file = {5951/Osborne_Roberts_2007_Gaussian processes for prediction.pdf},
}

@article{nickson_automated_2014,
	title = {Automated {Machine} {Learning} on {Big} {Data} using {Stochastic} {Algorithm} {Tuning}},
	url = {http://arxiv.org/abs/1407.7969},
	abstract = {We introduce a means of automating machine learning (ML) for big data tasks, by performing scalable stochastic Bayesian optimisation of ML algorithm parameters and hyper-parameters. More often than not, the critical tuning of ML algorithm parameters has relied on domain expertise from experts, along with laborious hand-tuning, brute search or lengthy sampling runs. Against this background, Bayesian optimisation is finding increasing use in automating parameter tuning, making ML algorithms accessible even to non-experts. However, the state of the art in Bayesian optimisation is incapable of scaling to the large number of evaluations of algorithm performance required to fit realistic models to complex, big data. We here describe a stochastic, sparse, Bayesian optimisation strategy to solve this problem, using many thousands of noisy evaluations of algorithm performance on subsets of data in order to effectively train algorithms for big data. We provide a comprehensive benchmarking of possible sparsification strategies for Bayesian optimisation, concluding that a Nystrom approximation offers the best scaling and performance for real tasks. Our proposed algorithm demonstrates substantial improvement over the state of the art in tuning the parameters of a Gaussian Process time series prediction task on real, big data.},
	journal = {arXiv preprint arXiv:1407.7969},
	author = {Nickson, Thomas and Osborne, Michael A. and Reece, Steven and Roberts, Stephen J.},
	year = {2014},
	note = {https://is.gd/e3JAVg},
	keywords = {preprint},
	file = {5746/Nickson et al_2014_Automated Machine Learning on Big Data using Stochastic Algorithm Tuning.pdf},
}

@article{salas_variational_2015,
	title = {A {Variational} {Bayesian} {State}-{Space} {Approach} to {Online} {Passive}-{Aggressive} {Regression}},
	url = {http://arxiv.org/abs/1509.02438},
	abstract = {Online Passive-Aggressive (PA) learning is a class of online margin-based algorithms suitable for a wide range of real-time prediction tasks, including classification and regression. PA algorithms are formulated in terms of deterministic point-estimation problems governed by a set of user-defined hyperparameters: the approach fails to capture model/prediction uncertainty and makes their performance highly sensitive to hyperparameter configurations. In this paper, we introduce a novel PA learning framework for regression that overcomes the above limitations. We contribute a Bayesian state-space interpretation of PA regression, along with a novel online variational inference scheme, that not only produces probabilistic predictions, but also offers the benefit of automatic hyperparameter tuning. Experiments with various real-world data sets show that our approach performs significantly better than a more standard, linear Gaussian state-space model.},
	journal = {arXiv:1509.02438 [stat]},
	author = {Salas, Arnold and Roberts, Stephen J. and Osborne, Michael A.},
	month = sep,
	year = {2015},
	keywords = {preprint},
	file = {5545/Salas et al_2015_A Variational Bayesian State-Space Approach to Online Passive-Aggressive.pdf},
}

@article{rizvi_novel_2017,
	title = {A {Novel} {Approach} to {Forecasting} {Financial} {Volatility} with {Gaussian} {Process} {Envelopes}},
	url = {https://arxiv.org/abs/1705.00891},
	abstract = {In this paper we use Gaussian Process (GP) regression to propose a novel approach for predicting volatility of financial returns by forecasting the envelopes of the time series. We provide a direct comparison of their performance to traditional approaches such as GARCH. We compare the forecasting power of three approaches: GP regression on the absolute and squared returns; regression on the envelope of the returns and the absolute returns; and regression on the envelope of the negative and positive returns separately. We use a maximum a posteriori estimate with a Gaussian prior to determine our hyperparameters. We also test the effect of hyperparameter updating at each forecasting step. We use our approaches to forecast out-of-sample volatility of four currency pairs over a 2 year period, at half-hourly intervals. From three kernels, we select the kernel giving the best performance for our data. We use two published accuracy measures and four statistical loss functions to evaluate the forecasting ability of GARCH vs GPs. In mean squared error the GP's perform 20\% better than a random walk model, and 50\% better than GARCH for the same data.},
	urldate = {2017-06-21},
	journal = {arXiv preprint arXiv:1705.00891},
	author = {Rizvi, Syed Ali Asad and Roberts, Stephen J. and Osborne, Michael A. and Nyikosa, Favour},
	year = {2017},
	keywords = {preprint},
	file = {5389/Rizvi et al_2017_A Novel Approach to Forecasting Financial Volatility with Gaussian Process.pdf},
}

@article{mcleod_practical_2017,
	title = {Practical {Bayesian} {Optimization} for {Variable} {Cost} {Objectives}},
	url = {http://arxiv.org/abs/1703.04335},
	abstract = {We propose a novel Bayesian Optimization approach for black-box functions with an environmental variable whose value determines the tradeoff between evaluation cost and the fidelity of the evaluations. Further, we use a novel approach to sampling support points, allowing faster construction of the acquisition function. This allows us to achieve optimization with lower overheads than previous approaches and is implemented for a more general class of problem. We show this approach to be effective on synthetic and real world benchmark problems.},
	urldate = {2017-06-30},
	journal = {arXiv:1703.04335 [stat]},
	author = {McLeod, Mark and Osborne, Michael A. and Roberts, Stephen J.},
	month = mar,
	year = {2017},
	note = {https://github.com/markm541374/gpbo},
	keywords = {preprint},
	file = {5367/McLeod et al_2017_Practical Bayesian Optimization for Variable Cost Objectives.pdf},
}

@article{rontsis_distributionally_2017,
	title = {Distributionally {Ambiguous} {Optimization} {Techniques} in {Batch} {Bayesian} {Optimization}},
	url = {http://arxiv.org/abs/1707.04191},
	abstract = {We propose a novel, theoretically-grounded, acquisition function for batch Bayesian optimization informed by insights from distributionally ambiguous optimization. Our acquisition function is a lower bound on the well-known Expected Improvement function -- which requires a multi-dimensional Gaussian Expectation over a piecewise affine function -- and is computed by evaluating instead the best-case expectation over all probability distributions consistent with the same mean and variance as the original Gaussian distribution. Unlike alternative approaches including Expected Improvement, our proposed acquisition function avoids multi-dimensional integrations entirely, and can be computed exactly as the solution of a convex optimization problem in the form of a tractable semidefinite program (SDP). Moreover, we prove that the solution of this SDP also yields exact numerical derivatives, which enable efficient optimization of the acquisition function. Finally, it efficiently handles marginalized posteriors with respect to the Gaussian Process' hyperparameters. We demonstrate superior performance to heuristic alternatives and approximations of the intractable expected improvement, justifying this performance difference based on simple examples that break the assumptions of state-of-the-art methods.},
	urldate = {2017-10-31},
	journal = {arXiv:1707.04191 [stat]},
	author = {Rontsis, Nikitas and Osborne, Michael A. and Goulart, Paul J.},
	month = jul,
	year = {2017},
	note = {https://github.com/oxfordcontrol/Bayesian-Optimization},
	keywords = {Statistics - Machine Learning, preprint},
	file = {5321/Rontsis et al_2017_Distributionally Ambiguous Optimization Techniques in Batch Bayesian.pdf},
}

@article{zhao_quantum_2018,
	title = {Quantum algorithms for training {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1803.10520},
	abstract = {Gaussian processes (GPs) are important models in supervised machine learning. Training in Gaussian processes refers to selecting the covariance functions and the associated parameters in order to improve the outcome of predictions, the core of which amounts to evaluating the logarithm of the marginal likelihood (LML) of a given model. LML gives a concrete measure of the quality of prediction that a GP model is expected to achieve. The classical computation of LML typically carries a polynomial time overhead with respect to the input size. We propose a quantum algorithm that computes the logarithm of the determinant of a Hermitian matrix, which runs in logarithmic time for sparse matrices. This is applied in conjunction with a variant of the quantum linear system algorithm that allows for logarithmic time computation of the form \${\textbackslash}mathbf\{y\}{\textasciicircum}TA{\textasciicircum}\{-1\}{\textbackslash}mathbf\{y\}\$, where \${\textbackslash}mathbf\{y\}\$ is a dense vector and \$A\$ is the covariance matrix. We hence show that quantum computing can be used to estimate the LML of a GP with exponentially improved efficiency under certain conditions.},
	urldate = {2018-03-29},
	journal = {arXiv:1803.10520 [quant-ph, stat]},
	author = {Zhao, Zhikuan and Fitzsimons, Jack K. and Osborne, Michael A. and Roberts, Stephen J. and Fitzsimons, Joseph F.},
	month = mar,
	year = {2018},
	keywords = {Computer Science - Learning, Quantum Physics, Statistics - Machine Learning, preprint},
	file = {5241/Zhao et al_2018_Quantum algorithms for training Gaussian Processes.pdf},
}

@article{nyikosa_bayesian_2018,
	title = {Bayesian {Optimization} for {Dynamic} {Problems}},
	url = {http://arxiv.org/abs/1803.03432},
	abstract = {We propose practical extensions to Bayesian optimization for solving dynamic problems. We model dynamic objective functions using spatiotemporal Gaussian process priors which capture all the instances of the functions over time. Our extensions to Bayesian optimization use the information learnt from this model to guide the tracking of a temporally evolving minimum. By exploiting temporal correlations, the proposed method also determines when to make evaluations, how fast to make those evaluations, and it induces an appropriate budget of steps based on the available information. Lastly, we evaluate our technique on synthetic and real-world problems.},
	urldate = {2018-04-16},
	journal = {arXiv:1803.03432 [stat]},
	author = {Nyikosa, Favour M. and Osborne, Michael A. and Roberts, Stephen J.},
	month = mar,
	year = {2018},
	keywords = {Statistics - Machine Learning, preprint},
	file = {5251/Nyikosa et al_2018_Bayesian Optimization for Dynamic Problems.pdf},
}

@article{granziol_entropic_2018,
	title = {Entropic {Spectral} {Learning} in {Large} {Scale} {Networks}},
	url = {http://arxiv.org/abs/1804.06802},
	abstract = {We present a novel algorithm for learning the spectral density of large scale networks using stochastic trace estimation and the method of maximum entropy. The complexity of the algorithm is linear in the number of non-zero elements of the matrix, offering a computational advantage over other algorithms. We apply our algorithm to the problem of community detection in large networks. We show state-of-the-art performance on both synthetic and real datasets.},
	urldate = {2018-04-19},
	journal = {arXiv:1804.06802 [cs, math, stat]},
	author = {Granziol, Diego and Ru, Binxin and Zohren, Stefan and Dong, Xiaowen and Osborne, Michael and Roberts, Stephen},
	month = apr,
	year = {2018},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, preprint, Computer Science - Information Theory},
	file = {5237/Granziol et al_2018_Entropic Spectral Learning in Large Scale Networks.pdf},
}

@article{paul_contextual_2018,
	title = {Contextual {Policy} {Optimisation}},
	url = {http://arxiv.org/abs/1805.10662},
	abstract = {Policy gradient methods have been successfully applied to a variety of reinforcement learning tasks. However, while learning in a simulator, these methods do not utilise the opportunity to improve learning by adjusting certain environment variables: unobservable state features that are randomly determined by the environment in a physical setting, but that are controllable in a simulator. This can lead to slow learning, or convergence to highly suboptimal policies. In this paper, we present contextual policy optimisation (CPO). The central idea is to use Bayesian optimisation to actively select the distribution of the environment variable that maximises the improvement generated by each iteration of the policy gradient method. To make this Bayesian optimisation practical, we contribute two easy-to-compute low-dimensional fingerprints of the current policy. We apply CPO to a number of continuous control tasks of varying difficulty and show that CPO can efficiently learn policies that are robust to significant rare events, which are unlikely to be observable under random sampling but are key to learning good policies.},
	urldate = {2018-05-29},
	journal = {arXiv:1805.10662 [cs, stat]},
	author = {Paul, Supratik and Osborne, Michael A. and Whiteson, Shimon},
	month = may,
	year = {2018},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning, Statistics - Machine Learning, preprint},
	file = {5222/Paul et al_2018_Contextual Policy Optimisation.pdf},
}

@article{nyikosa_adaptive_2019,
	title = {Adaptive {Configuration} {Oracle} for {Online} {Portfolio} {Selection} {Methods}},
	url = {http://arxiv.org/abs/1908.08258},
	abstract = {Financial markets are complex environments that produce enormous amounts of noisy and non-stationary data. One fundamental problem is online portfolio selection, the goal of which is to exploit this data to sequentially select portfolios of assets to achieve positive investment outcomes while managing risks. Various algorithms have been proposed for solving this problem in ﬁelds such as ﬁnance, statistics and machine learning, among others. Most of the methods have parameters that are estimated from backtests for good performance. Since these algorithms operate on nonstationary data that reﬂects the complexity of ﬁnancial markets, we posit that adaptively tuning these parameters in an intelligent manner is a remedy for dealing with this complexity. In this paper, we model the mapping between the parameter space and the space of performance metrics using a Gaussian process prior. We then propose an oracle based on adaptive Bayesian optimization for automatically and adaptively conﬁguring online portfolio selection methods. We test the efﬁcacy of our solution on algorithms operating on equity and index data from various markets.},
	language = {en},
	urldate = {2019-09-29},
	journal = {arXiv:1908.08258 [cs, stat]},
	author = {Nyikosa, Favour M. and Osborne, Michael A. and Roberts, Stephen J.},
	month = aug,
	year = {2019},
	keywords = {G.3, Statistics - Machine Learning, preprint, Computer Science - Machine Learning, 62P30},
	file = {5121/Nyikosa et al_2019_Adaptive Configuration Oracle for Online Portfolio Selection Methods.pdf},
}

@article{granziol_maximum_2019,
	title = {A {Maximum} {Entropy} approach to {Massive} {Graph} {Spectra}},
	url = {http://arxiv.org/abs/1912.09068},
	abstract = {Graph spectral techniques for measuring graph similarity, or for learning the cluster number, require kernel smoothing. The choice of kernel function and bandwidth are typically chosen in an ad-hoc manner and heavily affect the resulting output. We prove that kernel smoothing biases the moments of the spectral density. We propose an information theoretically optimal approach to learn a smooth graph spectral density, which fully respects the moment information. Our method's computational cost is linear in the number of edges, and hence can be applied to large networks, with millions of nodes. We apply our method to the problems to graph similarity and cluster number learning, where we outperform comparable iterative spectral approaches on synthetic and real graphs.},
	urldate = {2020-05-16},
	journal = {arXiv:1912.09068 [cs, stat]},
	author = {Granziol, Diego and Ru, Robin and Zohren, Stefan and Dong, Xiaowen and Osborne, Michael and Roberts, Stephen},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.09068},
	keywords = {Statistics - Machine Learning, preprint, Computer Science - Machine Learning},
	file = {5115/Granziol et al_2019_A Maximum Entropy approach to Massive Graph Spectra.pdf},
}

@article{severin_cross-architecture_2021,
	title = {Cross-architecture {Tuning} of {Silicon} and {SiGe}-based {Quantum} {Devices} {Using} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2107.12975},
	abstract = {The potential of Si and SiGe-based devices for the scaling of quantum circuits is tainted by device variability. Each device needs to be tuned to operation conditions. We give a key step towards tackling this variability with an algorithm that, without modification, is capable of tuning a 4-gate Si FinFET, a 5-gate GeSi nanowire and a 7-gate SiGe heterostructure double quantum dot device from scratch. We achieve tuning times of 30, 10, and 92 minutes, respectively. The algorithm also provides insight into the parameter space landscape for each of these devices. These results show that overarching solutions for the tuning of quantum devices are enabled by machine learning.},
	urldate = {2021-08-11},
	journal = {arXiv:2107.12975 [cond-mat, physics:quant-ph]},
	author = {Severin, B. and Lennon, D. T. and Camenzind, L. C. and Vigneau, F. and Fedele, F. and Jirovec, D. and Ballabio, A. and Chrastina, D. and Isella, G. and de Kruijf, M. and Carballido, M. J. and Svab, S. and Kuhlmann, A. V. and Braakman, F. R. and Geyer, S. and Froning, F. N. M. and Moon, H. and Osborne, M. A. and Sejdinovic, D. and Katsaros, G. and Zumbühl, D. M. and Briggs, G. A. D. and Ares, N.},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.12975},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Mesoscale and Nanoscale Physics, preprint, Quantum Physics},
	file = {6555/Severin et al_2021_Cross-architecture Tuning of Silicon and SiGe-based Quantum Devices Using.pdf},
}

@article{wagstaff_universal_2021,
	title = {Universal {Approximation} of {Functions} on {Sets}},
	url = {http://arxiv.org/abs/2107.01959},
	abstract = {Modelling functions of sets, or equivalently, permutation-invariant functions, is a long-standing challenge in machine learning. Deep Sets is a popular method which is known to be a universal approximator for continuous set functions. We provide a theoretical analysis of Deep Sets which shows that this universal approximation property is only guaranteed if the model's latent space is sufficiently high-dimensional. If the latent space is even one dimension lower than necessary, there exist piecewise-affine functions for which Deep Sets performs no better than a na{\textbackslash}"ive constant baseline, as judged by worst-case error. Deep Sets may be viewed as the most efficient incarnation of the Janossy pooling paradigm. We identify this paradigm as encompassing most currently popular set-learning methods. Based on this connection, we discuss the implications of our results for set learning more broadly, and identify some open questions on the universality of Janossy pooling in general.},
	urldate = {2021-08-11},
	journal = {arXiv:2107.01959 [cs, stat]},
	author = {Wagstaff, Edward and Fuchs, Fabian B. and Engelcke, Martin and Osborne, Michael A. and Posner, Ingmar},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.01959},
	keywords = {Computer Science - Machine Learning, preprint, Statistics - Machine Learning},
	file = {6558/Wagstaff et al_2021_Universal Approximation of Functions on Sets.pdf},
}

@article{hamid_marginalising_2021,
	title = {Marginalising over {Stationary} {Kernels} with {Bayesian} {Quadrature}},
	url = {http://arxiv.org/abs/2106.07452},
	abstract = {Marginalising over families of Gaussian Process kernels produces flexible model classes with well-calibrated uncertainty estimates. Existing approaches require likelihood evaluations of many kernels, rendering them prohibitively expensive for larger datasets. We propose a Bayesian Quadrature scheme to make this marginalisation more efficient and thereby more practical. Through use of the maximum mean discrepancies between distributions, we define a kernel over kernels that captures invariances between Spectral Mixture (SM) Kernels. Kernel samples are selected by generalising an information-theoretic acquisition function for warped Bayesian Quadrature. We show that our framework achieves more accurate predictions with better calibrated uncertainty than state-of-the-art baselines, especially when given limited (wall-clock) time budgets.},
	urldate = {2021-08-11},
	journal = {arXiv:2106.07452 [cs, stat]},
	author = {Hamid, Saad and Schulze, Sebastian and Osborne, Michael A. and Roberts, Stephen J.},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.07452},
	keywords = {Computer Science - Machine Learning, preprint, Statistics - Machine Learning},
	file = {6571/Hamid et al_2021_Marginalising over Stationary Kernels with Bayesian Quadrature.pdf},
}

@article{bueren_personalized_2021,
	title = {Personalized {Closed}-{Loop} {Brain} {Stimulation} for {Effective} {Neurointervention} {Across} {Participants}},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.18.436018v1},
	abstract = {Accumulating evidence from human-based research has highlighted that the prevalent one-size-fits-all approach for neural and behavioral interventions is inefficient. This approach can benefit one individual, but be ineffective or even detrimental for another. Studying the efficacy of the large range of different parameters for different individuals is costly, time-consuming and requires a large sample size that makes such research impractical and hinders effective interventions. Here an active machine learning technique is presented across participants—personalized Bayesian optimization (pBO)—that searches available parameter combinations to optimize an intervention as a function of an individual’s ability. This novel technique was utilized to identify transcranial alternating current stimulation frequency and current strength combinations most likely to improve arithmetic performance, based on a subject’s baseline arithmetic abilities. The pBO was performed across all subjects tested, building a model of subject performance, capable of recommending parameters for future subjects based on their baseline arithmetic ability. pBO successfully searches, learns, and recommends parameters for an effective neurointervention as supported by behavioral, stimulation, and neural data. The application of pBO in human-based research opens up new avenues for personalized and more effective interventions, as well as discoveries of protocols for treatment and translation to other clinical and non-clinical domains.},
	language = {en},
	urldate = {2021-08-11},
	author = {Bueren, Nienke E. R. van and Reed, Thomas L. and Nguyen, Vu and Sheffield, James G. and Ven, Sanne H. G. van der and Osborne, Michael A. and Kroesbergen, Evelyn H. and Kadosh, Roi Cohen},
	month = mar,
	year = {2021},
	keywords = {preprint},
	pages = {2021.03.18.436018},
	file = {6588/Bueren et al_2021_Personalized Closed-Loop Brain Stimulation for Effective Neurointervention.pdf},
}

@techreport{frey_technology_2015,
	type = {Citi {GPS} {Report}},
	title = {Technology at {Work}: {The} {Future} of {Innovation} and {Employment}},
	shorttitle = {Technology at {Work}},
	url = {http://www.oxfordmartin.ox.ac.uk/publications/view/1883},
	abstract = {Technology at Work: The Future of Innovation and Employment, is the latest Citi GPS report from the Oxford Martin School and Citi. It explores trends in automation and points to sluggish job creation caused partly by increasing automation, and argues that secular stagnation in the digital age can only be avoided by a shift towards inclusive growth.

The authors highlight the key challenges, explore some of the new technology brought on by the digital age and set out an agenda for change, calling for long term thinking to mitigate the negative effects of an ever more automated and digital economy.

Technology at Work marks the start of a new programme of research supported by Citi, the Oxford Martin Programme on Technology and Employment.},
	author = {Frey, Carl Benedikt and Osborne, Michael A},
	year = {2015},
	file = {1480/GPS_final.pdf}
}

@techreport{frey_agiletown_2014,
	title = {Agiletown : the relentless march of technology and {London}’s response},
	url = {http://www.deloitte.com/view/en_GB/uk/market-insights/uk-futures/london-futures/index.htm},
	abstract = {Our London Futures insights series focuses on the London economy and what it needs to do to maintain and reinforce its position as a leading global business hub. Our latest report in the programme, Agiletown: the relentless march of technology and London’s response, focuses on the challenges and opportunities that technology presents to London.

The findings indicate that a significant shift is occurring in the labour market. Jobs that do not need to be done in London, or can be fully replaced by technology, will continue to leave the city. However, the job losses will be outweighed by new jobs requiring skills that involve creativity, complex problem-solving and high technical content.

The report brings together research from Oxford Martin School academics Carl Benedikt Frey and Michael A Osborne on the potential impact of automation on jobs in the UK and London over the next two decades, and a Deloitte survey of 100 London based organisations, exploring the new jobs that will be created, the skills that will be needed, and the implications for current working practices.},
	institution = {Deloitte},
	author = {Frey, Carl Benedikt and Osborne, Michael A.},
	month = oct,
	year = {2014},
	file = {1892/uk-london-futures-agiletown-nov-14.pdf}
}

@techreport{bakhshi_creativity_2015,
	title = {Creativity {Vs} {Robots}},
	url = {http://www.nesta.org.uk/publications/creativity-vs-robots},
	abstract = {This report explores future automation and creativity in the UK and US workforces. We find that creative jobs will be much more resistant to automation than most other jobs.},
	urldate = {2015-04-24},
	institution = {Nesta},
	author = {Bakhshi, Hasan and Frey, Carl Benedikt and Osborne, Michael A.},
	year = {2015},
	file = {1866/creativity_vs._robots_wv.pdf}
}

@techreport{frey_technology_2016,
	type = {Citi {GPS} {Report}},
	title = {Technology at {Work} v2: {The} {Future} {Is} {Not} {What} {It} {Used} to {Be}},
	shorttitle = {Technology at {Work} v2.0},
	url = {http://www.oxfordmartin.ox.ac.uk/publications/view/2092},
	abstract = {Technology at Work v2.0: The Future Is Not What It Used to Be, produced by the Oxford Martin School and Citi, provides in-depth analysis of the vulnerabilities of countries and cities to job automation, explores what automation will mean for traditional models of economic growth, and considers how governments can prepare for the potentially disruptive impacts of job automation on society.

It builds on 2013 research by Carl Benedikt Frey and Michael Osborne which found that 47 per cent of US jobs were at risk of automation over the next two decades, and on the first Technology at Work Citi GPS report, published in 2015. 

As well as collaborating on the Citi GPS series of reports, the School has partnered with Citi to create a new programme of research, the Oxford Martin Programme on Technology and Employment, to investigate the implications of a rapidly changing technological landscape for economies and societies.},
	author = {Frey, Carl Benedikt and Osborne, Michael A.},
	year = {2016},
	file = {1204/Citi_GPS_Technology_Work_2.pdf}
}

@techreport{bakhshi_future_2017,
	address = {United Kingdom},
	title = {The future of skills: employment in 2030},
	shorttitle = {The future of skills},
	url = {https://futureskills.pearson.com},
	abstract = {Recent debates about the future of jobs have mainly focused on whether or not they are at risk of automation. Studies have generally minimised the potential effects of automation on job creation, and have tended to ignore other relevant trends, including globalisation, population ageing, urbanisation, and the rise of the green economy. This study uses a novel and comprehensive method to map out how employment is likely to change, and the implications for skills. --Executive summary.},
	language = {English},
	institution = {Pearson},
	author = {Bakhshi, Hasan and Downing, Jonathan M and Osborne, Michael A and Schneider, Philippe},
	year = {2017},
	file = {2864/Bakhshi et al. - 2017 - The future of skills employment in 2030.pdf}
}
@inproceedings{calliess_towards_2012,
	title = {Towards auction-based multi-agent collision-avoidance under continuous stochastic dynamics},
	abstract = {We describe an approach to multi-agent planning under continuous stochastic dynamics. The approach yields collision-free state tra jectories with adjustably high certainty, while aiming for low social cost. To this end we describe a collision-detection module based on a distribution-independent probabilistic bound. We employ an optimization-based approach to incrementally alter plans until all collisions are avoided with sufficiently high confidence. We consider the case of feedback controlled agents, and alter plans by introducing new setpoints to the agents’ controllers. In the context of a simple stochastic path planning scenario, we compare two alternative strategies for finding such setpoints.
Due to their practical importance, multi-agent collision avoidance and control have been extensively studied across different communities including AI, robotics and control. However, these works typically assume linear and discrete dynamic models; by contrast, our work intends to overcome these limitations and to present solutions for continuous state space. While our current experiments were conducted with linear stochastic differential equation (SDE) models with state-independent noise (yielding Gaussian processes) our method is also applicable to non-Gaussian cases with state-dependent uncertainties.
To ensure collision avoidance yields low social cost across the entire agent collective, we compare two different coordination mechanisms. Firstly, we consider a simple fixed-priority scheme Erdmann \& Lozano-Perez (1987), and secondly, we modify an auction-based coordination protocol Calliess et al. (2011) to work in our continuous setting. In contrast to pre-existing work in auction-style multi-agent planning (e.g. Tovey et al. (2005); Lagoudakis et al. (2005); Calliess et al. (2011)) and multi-agent collision avoidance (e.g. Kostic et al. (2010); Ayanian \& Kumar (2010)), we avoid a priori discretizations of space and time and present solutions for continuous time and state space.},
	booktitle = { {ICML}-2012, {Workshop} on {Markets}, {Mechanisms}, and {Multi}-{Agent} {Models}-{Examining} the {Interaction} of {Machine} {Learning} and {Economics}},
	author = {Calliess, Jan-P. and Osborne, Michael A. and Roberts, Stephen J.},
	year = {2012},
	keywords = {workshop},
	file = {1668/calliess_ICML_workshop_2012.pdf}
}

@inproceedings{calliess_towards_2012-1,
	title = {Towards optimization-based multi-agent collision-avoidance under continuous stochastic dynamics},
	abstract = {In our ongoing work, we aim to control a team of agents so as to achieve a prescribed goal state while being confident that collisions with other agents are avoided. Each agent is associated with a feedback controlled plant, whose continuous state trajectories follow some stochastic differential dynamics. To this end we describe a collision-detection module based on a distribution-independent probabilistic bound and employ a fixed priority method to resolve collisions. Due to their practical importance, multi-agent collision avoidance and control have been extensively studied across different communities including AI, robotics and control. However, these works typically assume linear and discrete dynamic models; by contrast, our work intends to overcome these limitations and to present solutions for continuous state space. While our current experiments were conducted with linear stochastic differential equation (SDE) models with state-independent noise (yielding Gaussian processes) we believe that our approach could also be applicable to nonGaussian cases with state-dependent uncertainties.},
	booktitle = {Workshops at the {Twenty}-{Sixth} {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Calliess, Jan-Peter and Osborne, Michael A. and Roberts, Stephen},
	year = {2012},
	keywords = {workshop},
	file = {1935/TowardsOptimization.pdf}
}

@inproceedings{osborne_machine_2011,
	title = {A machine learning approach to pattern detection and prediction for environmental monitoring and water sustainability},
	abstract = {We describe one of the successful products of a research partnership among several academic institutions (CMU, Oxford and UBC) and a water monitoring company (Aquatic Informatics). Water monitoring sensors are very diverse and remotely distributed. They produce vast quantities of data. The data itself is nonlinear and nonstationary. In addition, unanticipated environmental conditions and limitations in the sensing and communications hardware cause the data to be corrupted by previously uncharacterized nonlinearities, missing observations, spikes and multiple discontinuities. To improve the quality of the data and the monitoring process, this paper introduces an approach that uses Gaussian processes and a general “fault bucket” to capture a priori uncharacterized faults, along with an approximate method for marginalizing the potential faultiness of all observations. This gives rise to an efficient, flexible algorithm for the detection and automatic correction of faults. The probabilistic nature of the method is ideal for reporting uncertainty estimates to human operators. The approach can also be applied to detect patterns, other than faults, which are of great environmental significance. We present a fish sustainability example, where specific patterns in water level need to be detected so that fish don’t get trapped and die in shallow pools.},
	booktitle = {Proc. {Workshop} on {Machine} {Learning} for {Global} {Challenges}},
	author = {Osborne, Michael A. and Garnett, Roman and Swersky, Kevin and de Freitas, Nando},
	year = {2011},
	note = {https://is.gd/9M0ZYE},
	keywords = {workshop},
	file = {1628/osborne_et_al_mlgc_2011.pdf}
}

@inproceedings{rainforth_bayesian_2015,
	title = {Bayesian {Optimization} for {Probabilistic} {Programs}},
	url = {http://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2015BOPP.pdf},
	abstract = {We outline a general purpose framework for black-box marginal maximum a pos- teriori estimation of probabilistic program variables using Bayesian optimization with Gaussian processes.  We introduce the concept of an optimization query, whereby a probabilistic program returns an infinite lazy sequence of increasingly optimal estimates, and explain how a general purpose program transformation would allow the evidence of any probabilistic program, and therefore any graphical model, to be optimized with respect to an arbitrary subset of its variables.},
	booktitle = {Workshop on "{Black} {Box} {Learning} and {Inference}" at {NIPS} 2015},
	author = {Rainforth, Tom and van de Meent, Jan-Willem and Osborne, Michael A. and Wood, Frank},
	year = {2015},
	keywords = {workshop},
	file = {1088/rainforth2015BOPP.pdf}
}

@inproceedings{gibson_nir_2011,
	title = { {NIR} {Transmission} {Spectra} of {HD}189733: {Application} of {Gaussian} {Processes} for {Removing} {Systematics}},
	volume = {2},
	url = {http://goo.gl/4DmFW4},
	abstract = {The interpretation of HST transmission spectroscopy signals has recently
been the subject of much debate, in particular the NIR NICMOS data of HD
189733. At optical wavelengths, a high-altitude haze has been confirmed
with both STIS and ACS, whereas the presence of molecules has been
claimed with NICMOS. However, this detection of molecules has been
disputed based on the ad hoc model used to remove the systematics, the
choice of which changes the interpretation of the transmission signal.
Here, we introduce a powerful new technique, Gaussian Processes (GPs),
to model the systematics and simultaneously extract the transmission
spectrum, and demonstrate its application to the NICMOS data. GPs are a
Bayesian technique widely used in the machine learning community, which
allow us to define a distribution over functions. Rather than impose a
strict, functional form of systematics correction, we marginalise over
potentially infinite numbers of basis functions, effectively inferring
the form of the systematics correction from the data itself. This
results in a more robust interpretation of the signal. We also present
similar analyses of HST/WFC3 observations of HD 189733, which bridge the
gap between the current optical and NIR spectrum.},
	booktitle = { {AAS}/{Division} for {Extreme} {Solar} {Systems} {Abstracts}},
	author = {Gibson, Neale and Aigrain, Suzanne and Roberts, Stephen J. and Evans, Tom and Osborne, Michael A. and Pont, Frederic and Sing, David K.},
	year = {2011},
	keywords = {workshop},
	pages = {1106}
}

@inproceedings{nyikosa_adaptive_2015,
	title = {Adaptive {Bayesian} {Optimisation} for {Online} {Portfolio} {Selection}},
	abstract = {We present a Bayesian approach for online portfolio selection, a fundamental problem in computational finance. We pose the problem as the global optimi- sation of an expensive, time-varying, black-box function. As the optimum is itself dynamic, we use a model that allows us to capture time-dependent patterns of the function and to provide sequential decision processes that enable us to select optimal portfolios to invest in an online manner.},
	booktitle = {Workshop on {Bayesian} {Optimization} at {NIPS} 2015},
	author = {Nyikosa, Favour and Osborne, Michael A. and Roberts, Stephen J.},
	year = {2015},
	keywords = {workshop},
	file = {1566/NyikosaOsborneRobertsNipsBayesopt2015.pdf}
}

@inproceedings{swersky_raiders_2013,
	title = {Raiders of the lost architecture\_ {Kernels} for {Bayesian} optimization in conditional parameter spaces},
	abstract = {In practical Bayesian optimization, we must often search over structures with differing numbers of parameters. For instance, we may wish to search over neural network architectures with an unknown number of layers. To relate performance data gathered for different architectures, we define a new kernel for conditional parameter spaces that explicitly includes information about which parameters are relevant in a given structure. We show that this kernel improves model quality and Bayesian optimization results over several simpler baseline kernels.},
	booktitle = { {NIPS} workshop on {Bayesian} {Optimization} in theory and practice ({BayesOpt}’13)},
	author = {Swersky, Kevin and Duvenaud, David and Snoek, Jasper and Hutter, Frank and Osborne, Michael A.},
	year = {2013},
	keywords = {preprint},
	file = {1173/hier-kern-workshop.pdf}
}

@inproceedings{aigrain_gaussian_2011,
	title = {Gaussian {Processes} : the {Next} {Step} in {Exoplanet} {Data} {Analysis}},
	volume = {2},
	abstract = {When searching for or characterising exoplanets, we typically need to isolate a deterministic signal from stochastic processes-astrophysical or instrumental" noise"-in time-series data. Gaussian processes (GPs) enable us to construct distributions over random functions, and to infer the properties of" signal" and" noise" in a way that is both flexible and robust.},
	booktitle = { {AAS}/{Division} for {Extreme} {Solar} {Systems} {Abstracts}},
	author = {Aigrain, Suzanne and Gibson, Neale P. and Roberts, Stephen J. and Evans, Tom and McQuillan, Amy and Reece, Steve and Osborne, Michael A.},
	year = {2011},
	keywords = {workshop},
	pages = {1105},
	file = {2053/algrain_suzanne.pdf}
}

@inproceedings{fruehwirt_gaussian_2017,
	title = {Gaussian process classification from multivariate spatio-temporal brain potential patterns in {Alzheimer}’s disease},
	abstract = {The diagnosis of Alzheimer’s disease (AD) in routine clinical practice is most commonly based on subjective clinical interpretations. Event-related potentials (ERPs) have been shown to reflect neu- rodegenerative processes in AD and might qualify as affordable and thereby widely available markers to facilitate the objectivization of AD assessment. Here, we present a novel method combining multivariate pattern analysis (MVPA) and Gaussian process classification (GP) and aim to de- velop ERP markers for two crucial AD classification problems, i.e., the prediction of rapid cognitive decline (RCD) and the distinction between carriers and non-carriers of the ε4 allele of the apolipoprotein E gene, the main genetic risk factor for AD.},
	booktitle = { {IJCAI} {BOOM} workshop},
	author = {Fruehwirt, Wolfgang and Zhang, Pengfei and Gerstgrasser, Matthias and Osborne, Michael A and Grossegger, Dieter and Schmidt, Reinhold and Benke, Thomas and Dal-Bianco, Peter and Ransmayr, Gerhard and Weydemann, Leonard and Garn, Heinrich and Waser, Markus and Roberts, Stephen J. and Dorffner, Georg},
	year = {2017},
	file = {2576/GPC_from_multivariate_spatio-temporal_brain_potential_patterns_in_AD.pdf}
}

@inproceedings{zhang_sensor_2017,
	title = {Sensor {Selection} and {Random} {Field} {Reconstruction} for {Robust} and {Cost}-effective {Heterogeneous} {Weather} {Sensor} {Networks} for the {Developing} {World}},
	url = {http://arxiv.org/abs/1711.04308},
	abstract = {We address the two fundamental problems of spatial field reconstruction and sensor selection in heterogeneous sensor networks: (i) how to efficiently perform spatial field reconstruction based on measurements obtained simultaneously from networks with both high and low quality sensors; and (ii) how to perform query based sensor set selection with predictive MSE performance guarantee. For the first problem, we developed a low complexity algorithm based on the spatial best linear unbiased estimator (S-BLUE). Next, building on the S-BLUE, we address the second problem, and develop an efficient algorithm for query based sensor set selection with performance guarantee. Our algorithm is based on the Cross Entropy method which solves the combinatorial optimization problem in an efficient manner.},
	urldate = {2017-11-17},
	booktitle = { {NIPS} 2017 {Workshop} on {Machine} {Learning} for the {Developing} {World}},
	author = {Zhang, Pengfei and Nevat, Ido and Peters, Gareth W. and Fruehwirt, Wolfgang and Huang, Yongchao and Anders, Ivonne and Osborne, Michael},
	month = nov,
	year = {2017},
	keywords = {Statistics - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
	file = {2734/Zhang et al. - 2017 - Sensor Selection and Random Field Reconstruction f.pdf}
}
@phdthesis{osborne_bayesian_2010,
	title = {Bayesian {Gaussian} {Processes} for {Sequential} {Prediction}, {Optimisation} and {Quadrature}},
	abstract = {We develop a family of Bayesian algorithms built around Gaussian processes for various problems posed by sensor networks. We firstly introduce an iterative Gaussian process for multi-sensor inference problems, and show how our algorithm is able to cope with data that may be noisy, missing, delayed and/or correlated. Our algorithm can also effectively manage data that features changepoints, such as sensor faults. Extensions to our algorithm allow us to tackle some of the decision problems faced in sensor networks, including observation scheduling. Along these lines, we also propose a general method of global optimisation, Gaussian process global optimisation (GPGO), and demonstrate how it may be used for sensor placement.

Our algorithms operate within a complete Bayesian probabilistic framework. As such, we show how the hyperparameters of our system can be marginalised by use of Bayesian quadrature, a principled method of approximate integration. Similar tech niques also allow us to produce full posterior distributions for any hyperparameters of interest, such as the location of changepoints. We frame the selection of the positions of the hyperparameter samples required by Bayesian quadrature as a decision prob lem, with the aim of minimising the uncertainty we possess about the values of the integrals we are approximating. Taking this approach, we have developed sampling for Bayesian quadrature (SBQ), a principled competitor to Monte Carlo methods.

We conclude by testing our proposals on real weather sensor networks. We further benchmark GPGO on a wide range of canonical test problems, over which it achieves a significant improvement on its competitors. Finally, the efficacy of SBQ is demonstrated in the context of both prediction and optimisation.},
	school = {PhD thesis, University of Oxford},
	author = {Osborne, Michael},
	year = {2010},
	file = {2160/full_thesis.pdf}
}