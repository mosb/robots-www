
@article{rajpaul_gaussian_2015,
	title = {A {Gaussian} process framework for modelling stellar activity signals in radial velocity data},
	volume = {452},
	issn = {0035-8711, 1365-2966},
	url = {http://mnras.oxfordjournals.org/content/452/3/2269},
	doi = {10.1093/mnras/stv1428},
	abstract = {To date, the radial velocity (RV) method has been one of the most productive techniques for detecting and confirming extrasolar planetary candidates. Unfortunately, stellar activity can induce RV variations which can drown out or even mimic planetary signals – and it is notoriously difficult to model and thus mitigate the effects of these activity-induced nuisance signals. This is expected to be a major obstacle to using next-generation spectrographs to detect lower mass planets, planets with longer periods, and planets around more active stars. Enter Gaussian processes (GPs) which, we note, have a number of attractive features that make them very well suited to disentangling stellar activity signals from planetary signals. We present here a GP framework we developed to model RV time series jointly with ancillary activity indicators (e.g. bisector velocity spans, line widths, chromospheric activity indices), allowing the activity component of RV time series to be constrained and disentangled from e.g. planetary components. We discuss the mathematical details of our GP framework, and present results illustrating its encouraging performance on both synthetic and real RV data sets, including the publicly available Alpha Centauri B data set.},
	language = {en},
	number = {3},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Rajpaul, Vinesh and Aigrain, Suzanne and Osborne, Michael A. and Reece, Steve and Roberts, Stephen J.},
	month = sep,
	year = {2015},
	keywords = {methods: data analysis, planetary systems, stars: activity, stars: individual: Alpha Centauri B, stars: individual: Gliese 15 A, techniques: radial velocities},
	pages = {2269--2291},
	file = {5543/Rajpaul et al_2015_A Gaussian process framework for modelling stellar activity signals in radial.pdf}
}

@article{hennig_probabilistic_2015,
	title = {Probabilistic {Numerics} and {Uncertainty} in {Computations}},
	volume = {471},
	issn = {1364-5021},
	url = {http://rspa.royalsocietypublishing.org/content/royprsa/471/2179/20150142.full.pdf?ijkey=wr6Ggr6GGGgbJYr&keytype=ref},
	doi = {10.1098/rspa.2015.0142},
	abstract = {We deliver a call to arms for probabilistic numerical methods: algorithms for numerical tasks, including linear algebra, integration, optimization and solving differential equations, that return uncertainties in their calculations. Such uncertainties, arising from the loss of precision induced by numerical calculation with limited time or hardware, are important for much contemporary science and industry. Within applications such as climate science and astrophysics, the need to make decisions on the basis of computations with large and complex data has led to a renewed focus on the management of numerical uncertainty. We describe how several seminal classic numerical methods can be interpreted naturally as probabilistic inference. We then show that the probabilistic view suggests new algorithms that can flexibly be adapted to suit application specifics, while delivering improved empirical performance. We provide concrete illustrations of the benefits of probabilistic numeric algorithms on real scientific problems from astrometry and astronomical imaging, while highlighting open problems with these new algorithms. Finally, we describe how probabilistic numerical methods provide a coherent framework for identifying the uncertainty in calculations performed with a combination of numerical algorithms (e.g. both numerical optimisers and differential equation solvers), potentially allowing the diagnosis (and control) of error sources in computations.},
	number = {2179},
	journal = {Proceedings of the Royal Society A},
	author = {Hennig, Philipp and Osborne, Michael A. and Girolami, Mark A.},
	year = {2015},
	file = {5645/Hennig et al_2015_Probabilistic Numerics and Uncertainty in Computations.pdf}
}

@article{garnett_sequential_2010,
	title = {Sequential {Bayesian} prediction in the presence of changepoints and faults},
	volume = {53},
	doi = {doi:10.1093/comjnl/bxq003},
	abstract = {We introduce a new sequential algorithm for making robust predictions in the presence of changepoints. Unlike previous approaches, which focus on the problem of detecting and locating changepoints, our algorithm focuses on the problem of making predictions even when such changes might be present. We introduce nonstationary covariance functions to be used in Gaussian process prediction that model such changes, and then proceed to demonstrate how to effectively manage the hyperparameters associated with those covariance functions. We further introduce covariance functions to be used in situations where our observation model undergoes changes, as is the case for sensor faults. By using Bayesian quadrature, we can integrate out the hyperparameters, allowing us to calculate the full marginal predictive distribution. Furthermore, if desired, the posterior distribution over putative changepoint locations can be calculated as a natural byproduct of our prediction algorithm.},
	number = {9},
	journal = {The Computer Journal},
	author = {Garnett, Roman and Osborne, Michael A. and Reece, Steven and Rogers, Alex and Roberts, Stephen J.},
	year = {2010},
	pages = {1430},
	file = {5910/Garnett et al_2010_Sequential Bayesian prediction in the presence of changepoints and faults.pdf}
}

@article{luca_photodegradation_2006,
	title = {Photodegradation of methylene blue using crystalline titanosilicate quantum-confined semiconductor},
	volume = {18},
	url = {http://pubs.acs.org/doi/abs/10.1021/cm052839p},
	doi = {10.1021/cm052839p},
	abstract = {Synthetic sitinakite contains in its structure a discrete wire-like sublattice of linked TiO6 octahedra. This sublattice is held apart by silicate tetrahedra forming one-dimensional channels that run down the c axis. The optical properties of this structural arrangement have been studied and compared with other titanosilicate phases, the best known being ETS-10. Thus, sitinakite which has twice the titanate wire diameter of ETS-10 has a band gap of 4.07 eV compared with 3.87 eV. The reduced electron−hole effective mass of the sitinakite quantum-confined system has been calculated through use of the effective mass model and compared with that of other titanosilicate materials. The sitinakite phase has been shown to effectively photodegrade methylene blue (MB) dye at pH 7 using visible light excitation and displays a higher degradation rate than TiO2 (Degussa, P25) under the same experimental conditions. On the contrary, under UV excitation, the photodegradation rate obtained using P25 is much higher than that using sitinakite. Given that the band edge of sitinkaite is significantly blue shifted compared with that of P25, photodegradation of MB using sitinakite is attributed to sensitization of the MB cationic dye which is strongly adsorbed onto the negatively charged sitinakite surfaces.},
	number = {26},
	journal = {Chemistry of materials},
	author = {Luca, Vittorio and Osborne, Michael A. and Sizgek, Devlet and Griffith, Christopher and Araujo, Paula Z.},
	year = {2006},
	pages = {6132--6138}
}

@article{gibson_gaussian_2012,
	title = {A {Gaussian} process framework for modelling instrumental systematics: application to transmission spectroscopy},
	volume = {419},
	doi = {10.1111/j.1365-2966.2011.19915.x},
	abstract = {Transmission spectroscopy, which consists of measuring the wavelength-dependent absorption of starlight by a planet’s atmosphere during a transit, is a powerful probe of atmospheric composition. However, the expected signal is typically orders of magnitude smaller than instrumental systematics, and the results are crucially dependent on the treatment of the latter. In this paper, we propose a new method to infer transit parameters in the presence of systematic noise using Gaussian processes, a technique widely used in the machine learning community for Bayesian regression and classification problems. Our method makes use of auxiliary information about the state of the instrument, but does so in a non-parametric manner, without imposing a specific dependence of the systematics on the instrumental parameters, and naturally allows for the correlated nature of the noise. We give an example application of the method to archival NICMOS transmission spectroscopy of the hot Jupiter HD 189733, which goes some way towards reconciling the controversy surrounding this dataset in the literature. Finally, we provide an appendix giving a general introduction to Gaussian processes for regression, in order to encourage their application to a wider range of problems.},
	number = {3},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Gibson, Neale P. and Aigrain, Suzanne and Roberts, Stephen J. and Evans, Tom and Osborne, Michael A. and Pont, Frederic},
	year = {2012},
	pages = {2683--2694},
	file = {5857/Gibson et al_2012_A Gaussian process framework for modelling instrumental systematics.pdf}
}

@article{ng_using_2014,
	title = {Using textons to rank crystallization droplets by the likely presence of crystals},
	volume = {70},
	issn = {1399-0047},
	url = {http://scripts.iucr.org/cgi-bin/paper?S1399004714017581},
	doi = {10.1107/S1399004714017581},
	abstract = {The visual inspection of crystallization experiments is an important yet time-consuming and subjective step in X-ray crystallography. Previously published studies have focused on automatically classifying crystallization droplets into distinct but ultimately arbitrary experiment outcomes; here, a method is described that instead ranks droplets by their likelihood of containing crystals or microcrystals, thereby prioritizing for visual inspection those images that are most likely to contain useful information. The use of textons is introduced to describe crystallization droplets objectively, allowing them to be scored with the posterior probability of a random forest classifier trained against droplets manually annotated for the presence or absence of crystals or microcrystals. Unlike multi- class classification, this two-class system lends itself naturally to unidirectional ranking, which is most useful for assisting sequential viewing because images can be arranged simply by using these scores: this places droplets with probable crystal- line behaviour early in the viewing order. Using this approach, the top ten wells included at least one human-annotated crystal or microcrystal for 94\% of the plates in a data set of 196 plates imaged with a Minstrel HT system. The algorithm is robustly transferable to at least one other imaging system: when the parameters trained from Minstrel HT images are applied to a data set imaged by the Rock Imager system, human-annotated crystals ranked in the top ten wells for 90\% of the plates. Because rearranging images is fundamental to the approach, a custom viewer was written to seamlessly support such ranked viewing, along with another important output of the algorithm, namely the shape of the curve of scores, which is itself a useful overview of the behaviour of the plate; additional features with known usefulness were adopted from existing viewers. Evidence is presented that such ranked viewing of images allows faster but more accurate evaluation of drops, in particular for the identification of microcrystals.},
	number = {10},
	journal = {Acta Crystallographica Section D Biological Crystallography},
	author = {Ng, Jia Tsing and Dekker, Carien and Kroemer, Markus and Osborne, Michael A. and von Delft, Frank},
	month = oct,
	year = {2014},
	file = {5688/Ng et al_2014_Using textons to rank crystallization droplets by the likely presence of.pdf}
}

@article{richardson_gaussian_2017,
	title = {Gaussian process regression for forecasting battery state of health},
	volume = {357},
	issn = {0378-7753},
	url = {http://www.sciencedirect.com/science/article/pii/S0378775317306250},
	doi = {10.1016/j.jpowsour.2017.05.004},
	abstract = {Accurately predicting the future capacity and remaining useful life of batteries is necessary to ensure reliable system operation and to minimise maintenance costs. The complex nature of battery degradation has meant that mechanistic modelling of capacity fade has thus far remained intractable; however, with the advent of cloud-connected devices, data from cells in various applications is becoming increasingly available, and the feasibility of data-driven methods for battery prognostics is increasing. Here we propose Gaussian process (GP) regression for forecasting battery state of health, and highlight various advantages of GPs over other data-driven and mechanistic approaches. GPs are a type of Bayesian non-parametric method, and hence can model complex systems whilst handling uncertainty in a principled manner. Prior information can be exploited by GPs in a variety of ways: explicit mean functions can be used if the functional form of the underlying degradation model is available, and multiple-output GPs can effectively exploit correlations between data from different cells. We demonstrate the predictive capability of GPs for short-term and long-term (remaining useful life) forecasting on a selection of capacity vs. cycle datasets from lithium-ion cells.},
	journal = {Journal of Power Sources},
	author = {Richardson, Robert R. and Osborne, Michael A. and Howey, David A.},
	month = jul,
	year = {2017},
	keywords = {Ageing, Gaussian process regression, Lithium-ion battery, Prognostics, State-of-health},
	pages = {209--219},
	file = {5311/Richardson et al_2017_Gaussian process regression for forecasting battery state of health.pdf}
}

@article{osborne_real-time_2012,
	title = {Real-{Time} {Information} {Processing} of {Environmental} {Sensor} {Network} {Data}},
	volume = {9},
	doi = {10.1145/2379799.2379800},
	abstract = {In this paper, we consider the problem faced by a sensor network operator who must infer, in real-time, the value of some environmental parameter that is being monitored at discrete points in space and time by a sensor network. We describe a powerful and generic approach built upon an efficient multi-output Gaussian process that facilitates this information acquisition and processing. Our algorithm allows effective inference even with minimal domain knowledge, and we further introduce a formulation of Bayesian Monte Carlo to permit the principled management of the hyperparameters introduced by our flexible models. We demonstrate how our methods can be applied in cases where the data is delayed, intermittently missing, censored and/or correlated. We validate our approach using data collected from three networks of weather sensors and show that it yields better inference performance than both conventional independent Gaussian processes and the Kalman filter. Finally, we show that our formalism efficiently re-uses previous computations by following an online update procedure as new data sequentially arrives, and that this results in a four-fold increase in computational speed in the largest cases considered.},
	number = {1},
	journal = {ACM Transactions on Sensor Networks},
	author = {Osborne, Michael A. and Roberts, Stephen J. and Rogers, Alex and Jennings, Nicholas R.},
	year = {2012},
	pages = {1:1--1:32},
	file = {5841/Osborne et al_2012_Real-Time Information Processing of Environmental Sensor Network Data.pdf}
}

@article{roberts_gaussian_2013,
	title = {Gaussian processes for time-series modelling},
	volume = {371},
	doi = {10.1098/rsta.2011.0550},
	abstract = {In this paper we offer a gentle introduction to Gaussian processes for timeseries data analysis. The conceptual framework of Bayesian modelling for timeseries data is discussed and the foundations of Bayesian non-parametric modelling presented for Gaussian processes. We discuss how domain knowledge influences design of the Gaussian process models and provide case examples to highlight the approaches.},
	number = {1984},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Roberts, Stephen J. and Osborne, Michael A. and Ebden, Mark and Reece, Steve and Gibson, Neale P. and Aigrain, Suzanne},
	year = {2013},
	pages = {20110550},
	file = {5807/Roberts et al_2013_Gaussian processes for time-series modelling.pdf}
}

@article{mann_objectively_2011,
	title = {Objectively identifying landmark use and predicting flight trajectories of the homing pigeon using {Gaussian} processes},
	volume = {8},
	doi = {10.1098/rsif.2010.0301},
	abstract = {Pigeons home along idiosyncratic habitual routes from familiar locations. It has been suggested that memorized visual landmarks underpin this route learning. However, the inability to experimentally alter the landscape on large scales has hindered the discovery of the particular features to which birds attend. Here, we present a method for objectively classifying the most informative regions of animal paths. We apply this method to flight trajectories from homing pigeons to identify probable locations of salient visual landmarks. We construct and apply a Gaussian process model of flight trajectory generation for pigeons trained to home from specific release sites. The model shows increasing predictive power as the birds become familiar with the sites, mirroring the animal’s learning process. We subsequently find that the most informative elements of the flight trajectories coincide with landscape features that have previously been suggested as important components of the homing task.},
	number = {55},
	journal = {Journal of The Royal Society Interface},
	author = {Mann, Richard and Freeman, Robin and Osborne, Michael A. and Garnett, Roman and Armstrong, Chris and Meade, Jessica and Biro, Dora and Guilford, Tim and Roberts, Stephen J.},
	year = {2011},
	pages = {210--219},
	file = {5874/Mann et al_2011_Objectively identifying landmark use and predicting flight trajectories of the.pdf}
}

@article{frey_future_2017,
	title = {The future of employment: {How} susceptible are jobs to computerisation?},
	volume = {114},
	issn = {0040-1625},
	shorttitle = {The future of employment},
	url = {http://www.sciencedirect.com/science/article/pii/S0040162516302244},
	doi = {10.1016/j.techfore.2016.08.019},
	abstract = {We examine how susceptible jobs are to computerisation. To assess this, we begin by implementing a novel methodology to estimate the probability of computerisation for 702 detailed occupations, using a Gaussian process classifier. Based on these estimates, we examine expected impacts of future computerisation on US labour market outcomes, with the primary objective of analysing the number of jobs at risk and the relationship between an occupations probability of computerisation, wages and educational attainment.},
	journal = {Technological Forecasting and Social Change},
	author = {Frey, Carl Benedikt and Osborne, Michael A.},
	month = jan,
	year = {2017},
	keywords = {Employment, Occupational choice, Skill demand, Technological change, wage inequality},
	pages = {254--280},
	file = {5383/Frey_Osborne_2017_The future of employment.pdf}
}

@article{zhang_spatial_2018,
	title = {Spatial {Field} {Reconstruction} and {Sensor} {Selection} in {Heterogeneous} {Sensor} {Networks} with {Stochastic} {Energy} {Harvesting}},
	url = {http://arxiv.org/abs/1801.05356},
	abstract = {We address the two fundamental problems of spatial field reconstruction and sensor selection in het- erogeneous sensor networks. We consider the case where two types of sensors are deployed: the first consists of expensive, high quality sensors; and the second, of cheap low quality sensors, which are activated only if the intensity of the spatial field exceeds a pre-defined activation threshold (eg. wind sensors). In addition, these sensors are powered by means of energy harvesting and their time varying energy status impacts on the accuracy of the measurement that may be obtained. We account for this phenomenon by encoding the energy harvesting process into the second moment properties of the additive noise, resulting in a spatial heteroscedastic process. We then address the following two important problems: (i) how to efficiently perform spatial field reconstruction based on measurements obtained simultaneously from both networks; and (ii) how to perform query based sensor set selection with predictive MSE performance guarantee. We first show that the resulting predictive posterior distribution, which is key in fusing such disparate observations, involves solving intractable integrals. To overcome this problem, we solve the first problem by developing a low complexity algorithm based on the spatial best linear unbiased estimator (S-BLUE). Next, building on the S-BLUE, we address the second problem, and develop an efficient algorithm for query based sensor set selection with performance guarantee. Our algorithm is based on the Cross Entropy method which solves the combinatorial optimization problem in an efficient manner. We present a comprehensive study of the performance gain that can be obtained by augmenting the high-quality sensors with low-quality sensors using both synthetic and real insurance storm surge database known as the Extreme Wind Storms Catalogue.},
	journal = {IEEE Transactions on Signal Processing},
	author = {Zhang, Pengfei and Nevat, Ido and Peters, Gareth W. and Septier, Francois and Osborne, Michael A.},
	year = {2018},
	keywords = {Electrical Engineering and Systems Science - Signal Processing},
	file = {5279/Zhang et al_2018_Spatial Field Reconstruction and Sensor Selection in Heterogeneous Sensor.pdf}
}

@article{richardson_gaussian_2018,
	title = {Gaussian {Process} {Regression} for {In}-situ {Capacity} {Estimation} of {Lithium}-ion {Batteries}},
	issn = {1551-3203, 1941-0050},
	url = {http://ieeexplore.ieee.org/document/8263147/},
	doi = {10.1109/TII.2018.2794997},
	abstract = {Accurate on-board capacity estimation is of critical importance in lithium-ion battery applications. Battery charg- ing/discharging often occurs under a constant current load, and hence voltage vs. time measurements under this condition may be accessible in practice. This paper presents a data-driven diagnostic technique, Gaussian Process regression for In-situ Capacity Estimation (GP-ICE), which estimates battery capacity using voltage measurements over short periods of galvanostatic operation. Unlike previous works, GP-ICE does not rely on interpreting the voltage-time data as Incremental Capacity (IC) or Differential Voltage (DV) curves. This overcomes the need to differentiate the voltage-time data (a process which amplifies measurement noise), and the requirement that the range of voltage measurements encompasses the peaks in the IC/DV curves. GP-ICE is applied to two datasets, consisting of 8 and 20 cells respectively. In each case, within certain voltage ranges, as little as 10 seconds of galvanostatic operation enables capacity estimates with approximately 2–3 \% RMSE.},
	urldate = {2018-01-19},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Richardson, Robert R. and Birkl, Christoph R. and Osborne, Michael A. and Howey, David},
	year = {2018},
	pages = {1--1},
	file = {5284/Richardson et al_2018_Gaussian Process Regression for In-situ Capacity Estimation of Lithium-ion.pdf}
}

@article{sarkar_prediction_2018,
	title = {Prediction of tidal currents using {Bayesian} machine learning},
	volume = {158},
	issn = {0029-8018},
	url = {https://www.sciencedirect.com/science/article/pii/S0029801818302397},
	doi = {10.1016/j.oceaneng.2018.03.007},
	abstract = {We propose the use of machine learning techniques in the Bayesian framework for the prediction of tidal currents. Computer algorithms based on the classical harmonic analysis approach have been used for several decades in tidal predictions, however the method has several limitations in terms of handling of noise, expressing uncertainty, capturing non-sinusoidal, non-harmonic variations. There is a need for principled approaches which can handle uncertainty and accommodate noise in the data. In this work, we use Gaussian processes, a Bayesian non-parametric machine learning technique, to predict tidal currents. The probabilistic and non-parametric nature of the approach enables it to represent uncertainties in modelling and deal with complexities of the problem. The method makes use of kernel functions to capture structures in the data. The overall objective is to take advantage of the recent progress in machine learning to construct a robust algorithm. Using several sets of field data, we show that the machine learning approach can achieve better results than the traditional approaches.},
	urldate = {2018-04-13},
	journal = {Ocean Engineering},
	author = {Sarkar, Dripta and Osborne, Michael A. and Adcock, Thomas A. A.},
	month = jun,
	year = {2018},
	keywords = {Gaussian process, Machine learning, Prediction, Tidal currents},
	pages = {221--231},
	file = {5211/Sarkar et al_2018_Prediction of tidal currents using Bayesian machine learning.pdf}
}

@article{lee_optimal_2018,
	title = {Optimal operation of an energy management system using model predictive control and {Gaussian} process time-series modelling},
	issn = {2168-6777},
	url = {https://ieeexplore.ieee.org/document/8327585},
	doi = {10.1109/JESTPE.2018.2820071},
	abstract = {This paper describes an optimal operation scheme for energy management systems (EMS) using Gaussian process (GP) forecasting and model predictive control (MPC) in the context of grid-connected microgrids with local generation, loads and storage. The main objective of the control is to minimize the cost of energy taken from the grid. The microgrid consists of a PV panel and a battery energy storage system (ESS), which are connected to a power grid and a local load via a DC bus. At each sampling time, the predictions for PV output power and load demand power are calculated, and an MPC algorithm is executed based on these predictions and a physical battery model to decide the setpoint of the battery. Simulations of two case studies, namely, a lab scale microgrid and a commercial microgrid, are presented. We compare the performance of MPC with various horizon lengths to a rule-based control strategy to demonstrate a cost reduction of more than than 2\%.},
	journal = {IEEE J. Emerg. Sel. Topics Power Electron. IEEE Journal of Emerging and Selected Topics in Power Electronics},
	author = {Lee, Jaehwa and Zhang, Pengfei and Gan, Leong Kit and Howey, David A and Osborne, Michael A and Tosi, Alessandra and Duncan, Stephen},
	year = {2018},
	pages = {1},
	file = {5286/Lee et al_2018_Optimal operation of an energy management system using model predictive control.pdf}
}

@article{richardson_battery_2019,
	title = {Battery health prediction under generalized conditions using a {Gaussian} process transition model},
	volume = {23},
	issn = {2352-152X},
	url = {http://www.sciencedirect.com/science/article/pii/S2352152X18307734},
	doi = {10.1016/j.est.2019.03.022},
	abstract = {Accurately predicting the future health of batteries is necessary to ensure reliable operation, minimise maintenance costs, and calculate the value of energy storage investments. The complex nature of degradation renders data-driven approaches a promising alternative to mechanistic modelling. Here we show that a Bayesian non-parametric approach, using Gaussian process regression, can predict capacity fade in a variety of usage scenarios, forming a generalised health model. Our results are demonstrated on the open-source NASA Randomised Battery Usage Dataset, with data of 26 cells aged under widely varying operational conditions. Using half of the cells for training, and half for validation, we can accurately predict long term capacity fade, with a best case normalised root mean square error of 4.3\%, including accurate estimation of the uncertainty of the prediction.},
	urldate = {2019-04-23},
	journal = {Journal of Energy Storage},
	author = {Richardson, Robert R. and Osborne, Michael A. and Howey, David A.},
	month = jun,
	year = {2019},
	keywords = {Gaussian process regression, Prognostics, Battery, Degradation, Health, Lithium-ion},
	pages = {320--328},
	file = {5132/Richardson et al_2019_Battery health prediction under generalized conditions using a Gaussian process.pdf}
}

@article{sarkar_spatiotemporal_2019,
	title = {Spatiotemporal {Prediction} of {Tidal} {Currents} {Using} {Gaussian} {Processes}},
	volume = {124},
	issn = {2169-9275},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018JC014471},
	doi = {10.1029/2018JC014471},
	abstract = {Abstract Predicting fast tidal currents can be a challenging task. Unlike tidal water levels, currents can vary sharply over short distances. The classical approach of harmonic analysis can analyze data at point locations and there is a need for a method that can handle spatiotemporal data, as well as be robust to the uncertainty and noise inevitable in real-world measurements. In this work, we present a Bayesian machine learning (ML) approach to tackle the problem. The method is based on Gaussian processes, a nonparametric ML technique that uses a kernel function to capture structures in the data. A case study is performed using data from a validated numerical model simulating the tidal dynamics in the Pentland Firth region, UK. Several sampling strategies are explored and the case where measurement location is changed after every sampling is found to produce the lowest average error in the predictions. We show that the presented methodology using data from just a single moving data source can provide a better spatiotemporal description than traditional techniques using continuous data from a large number of locations. The work can be useful to developers of tidal energy farms, navigation, and other purposes.},
	number = {4},
	urldate = {2019-04-23},
	journal = {Journal of Geophysical Research: Oceans},
	author = {Sarkar, Dripta and Osborne, Michael A. and Adcock, Thomas A. A.},
	month = mar,
	year = {2019},
	keywords = {Gaussian process, machine learning, data sampling, oceanography, spatiotemporal modeling, tidal currents},
	pages = {2697--2715},
	file = {5158/Sarkar et al_2019_Spatiotemporal Prediction of Tidal Currents Using Gaussian Processes.pdf}
}

@article{briol_rejoinder_2019,
	title = {Rejoinder – {Probabilistic} {Integration}: {A} {Role} in {Statistical} {Computation}?},
	volume = {34},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Rejoinder},
	url = {https://projecteuclid.org/euclid.ss/1555056029},
	doi = {10.1214/18-STS683},
	abstract = {This article is the rejoinder for the paper “Probabilistic Integration: A Role in Statistical Computation?” (Statist. Sci. 34 (2019) 1–22). We would first like to thank the reviewers and many of our colleagues who helped shape this paper, the Editor for selecting our paper for discussion, and of course all of the discussants for their thoughtful, insightful and constructive comments. In this rejoinder, we respond to some of the points raised by the discussants and comment further on the fundamental questions underlying the paper: (i) Should Bayesian ideas be used in numerical analysis? and (ii) If so, what role should such approaches have in statistical computation?},
	language = {EN},
	number = {1},
	urldate = {2019-04-23},
	journal = {Statistical Science},
	author = {Briol, François-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A. and Sejdinovic, Dino},
	month = feb,
	year = {2019},
	keywords = {probabilistic numerics, Computational statistics, nonparametric statistics, uncertainty quantification},
	pages = {38--42},
	file = {5170/Briol et al_2019_Rejoinder – Probabilistic Integration.pdf}
}

@article{briol_probabilistic_2019,
	title = {Probabilistic {Integration}: {A} {Role} in {Statistical} {Computation}?},
	volume = {34},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Probabilistic {Integration}},
	url = {http://arxiv.org/abs/1512.00933},
	doi = {10.1214/18-STS660},
	abstract = {A research frontier has emerged in scientific computation, wherein discretisation error is regarded as a source of epistemic uncertainty that can be modelled. This raises several statistical challenges, including the design of statistical methods that enable the coherent propagation of probabilities through a (possibly deterministic) computational work-flow, in order to assess the impact of discretisation error on the computer output. This paper examines the case for probabilistic numerical methods in routine statistical computation. Our focus is on numerical integration, where a probabilistic integrator is equipped with a full distribution over its output that reflects the fact that the integrand has been discretised. Our main technical contribution is to establish, for the first time, rates of posterior contraction for one such method. Several substantial applications are provided for illustration and critical evaluation, including examples from statistical modelling, computer graphics and a computer model for an oil reservoir.},
	language = {EN},
	number = {1},
	urldate = {2019-04-23},
	journal = {Statistical Science},
	author = {Briol, François-Xavier and Oates, Chris J. and Girolami, Mark and Osborne, Michael A. and Sejdinovic, Dino},
	month = feb,
	year = {2019},
	note = {https://fxbriol.github.io/publications/www.warwick.ac.uk/fxbriol/probabilistic\_integration/code\_pi\_mar16.zip},
	keywords = {probabilistic numerics, Computational statistics, nonparametric statistics, uncertainty quantification},
	pages = {1--22},
	file = {5171/Briol et al_2019_Probabilistic Integration.pdf}
}

@article{granziol_meme:_2019,
	title = { {MEMe}: {An} {Accurate} {Maximum} {Entropy} {Method} for {Efficient} {Approximations} in {Large}-{Scale} {Machine} {Learning}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = { {MEMe}},
	url = {https://www.mdpi.com/1099-4300/21/6/551},
	doi = {10.3390/e21060551},
	abstract = {Efficient approximation lies at the heart of large-scale machine learning problems. In this paper, we propose a novel, robust maximum entropy algorithm, which is capable of dealing with hundreds of moments and allows for computationally efficient approximations. We showcase the usefulness of the proposed method, its equivalence to constrained Bayesian variational inference and demonstrate its superiority over existing approaches in two applications, namely, fast log determinant estimation and information-theoretic Bayesian optimisation.},
	language = {en},
	number = {6},
	urldate = {2019-05-31},
	journal = {Entropy},
	author = {Granziol, Diego and Ru, Binxin and Zohren, Stefan and Dong, Xiaowen and Osborne, Michael and Roberts, Stephen},
	month = jun,
	year = {2019},
	keywords = {Bayesian optimisation, log determinant estimation, maximum entropy},
	pages = {551},
	file = {5133/Granziol et al_2019_MEMe.pdf}
}

@article{lennon_efficiently_2019,
	title = {Efficiently measuring a quantum device using machine learning},
	volume = {5},
	copyright = {2019 The Author(s)},
	issn = {2056-6387},
	url = {https://www.nature.com/articles/s41534-019-0193-4},
	doi = {10.1038/s41534-019-0193-4},
	abstract = {Scalable quantum technologies such as quantum computers will require very large numbers of quantum devices to be characterised and tuned. As the number of devices on chip increases, this task becomes ever more time-consuming, and will be intractable on a large scale without efficient automation. We present measurements on a quantum dot device performed by a machine learning algorithm in real time. The algorithm selects the most informative measurements to perform next by combining information theory with a probabilistic deep-generative model that can generate full-resolution reconstructions from scattered partial measurements. We demonstrate, for two different current map configurations that the algorithm outperforms standard grid scan techniques, reducing the number of measurements required by up to 4 times and the measurement time by 3.7 times. Our contribution goes beyond the use of machine learning for data search and analysis, and instead demonstrates the use of algorithms to automate measurements. This works lays the foundation for learning-based automated measurement of quantum devices.},
	language = {en},
	number = {1},
	urldate = {2019-09-29},
	journal = {npj Quantum Information},
	author = {Lennon, D. T. and Moon, H. and Camenzind, L. C. and Yu, Liuqi and Zumbühl, D. M. and Briggs, G. a. D. and Osborne, M. A. and Laird, E. A. and Ares, N.},
	month = sep,
	year = {2019},
	pages = {1--8},
	file = {5118/Lennon et al_2019_Efficiently measuring a quantum device using machine learning.pdf}
}

@article{fitzsimons_general_2019,
	title = {A {General} {Framework} for {Fair} {Regression}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1099-4300/21/8/741},
	doi = {10.3390/e21080741},
	abstract = {Fairness, through its many forms and definitions, has become an important issue facing the machine learning community. In this work, we consider how to incorporate group fairness constraints into kernel regression methods, applicable to Gaussian processes, support vector machines, neural network regression and decision tree regression. Further, we focus on examining the effect of incorporating these constraints in decision tree regression, with direct applications to random forests and boosted trees amongst other widespread popular inference techniques. We show that the order of complexity of memory and computation is preserved for such models and tightly binds the expected perturbations to the model in terms of the number of leaves of the trees. Importantly, the approach works on trained models and hence can be easily applied to models in current use and group labels are only required on training data.},
	language = {en},
	number = {8},
	urldate = {2019-09-29},
	journal = {Entropy},
	author = {Fitzsimons, Jack and Al Ali, AbdulRahman and Osborne, Michael and Roberts, Stephen},
	month = aug,
	year = {2019},
	keywords = {Gaussian process, machine learning, kernel methods, algorithmic fairness, constrained learning, decision tree, neural network},
	pages = {741},
	file = {5122/Fitzsimons et al_2019_A General Framework for Fair Regression.pdf}
}

@article{zhao_quantum_2019,
	title = {Quantum algorithms for training {Gaussian} processes},
	volume = {100},
	url = {https://link.aps.org/doi/10.1103/PhysRevA.100.012304},
	doi = {10.1103/PhysRevA.100.012304},
	abstract = {Gaussian processes (GPs) are important models in supervised machine learning. Training in Gaussian processes refers to selecting the covariance functions and the associated parameters in order to improve the outcome of predictions, the core of which amounts to evaluating the logarithm of the marginal likelihood (LML) of a given model. The LML gives a concrete measure of the quality of prediction that a GP model is expected to achieve. The classical computation of the LML typically carries a polynomial time overhead with respect to the input size. We propose a quantum algorithm that computes the logarithm of the determinant of a Hermitian matrix, which runs in logarithmic time for sparse matrices. This is applied in conjunction with a variant of the quantum linear system algorithm that allows for logarithmic-time computation of the form yTA−1y, where y is a dense vector and A is the covariance matrix. We hence show that quantum computing can be used to estimate the LML of a GP with exponentially improved efficiency under certain conditions.},
	number = {1},
	urldate = {2019-09-29},
	journal = {Physical Review A},
	author = {Zhao, Zhikuan and Fitzsimons, Jack K. and Osborne, Michael A. and Roberts, Stephen J. and Fitzsimons, Joseph F.},
	month = jul,
	year = {2019},
	pages = {012304},
	file = {5125/Zhao et al_2019_Quantum algorithms for training Gaussian processes.pdf}
}

@article{willis_qualitative_2020,
	title = {Qualitative and quantitative approach to assess of the potential for automating administrative tasks in general practice},
	volume = {10},
	copyright = {© Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by-nc/4.0/This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
	issn = {2044-6055, 2044-6055},
	url = {https://bmjopen.bmj.com/content/10/6/e032412},
	doi = {10.1136/bmjopen-2019-032412},
	abstract = {Objective To identify the extent to which administrative tasks carried out by primary care staff in general practice could be automated.
Design A mixed-method design including ethnographic case studies, focus groups, interviews and an online survey of automation experts.
Setting Three urban and three rural general practice health centres in England selected for differences in list size and organisational characteristics.
Participants Observation and interviews with 65 primary care staff in the following job roles: administrator, manager, general practitioner, healthcare assistant, nurse practitioner, pharmacy technician, phlebotomist, practice nurse, pharmacist, prescription clerk, receptionist, scanning clerk, secretary and medical summariser; together with a survey of 156 experts in automation technologies.
Methods 330 hours of ethnographic observation and documentation of administrative tasks carried out by staff in each of the above job roles, followed by coding and classification; semistructured interviews with 10 general practitioners and 6 staff focus groups. The online survey of machine learning, artificial intelligence and robotics experts was analysed using an ordinal Gaussian process prediction model to estimate the automatability of the observed tasks.
Results The model predicted that roughly 44\% of administrative tasks carried out by staff in general practice are ‘mostly’ or ‘completely’ automatable using currently available technology. Discussions with practice staff underlined the need for a cautious approach to implementation.
Conclusions There is considerable potential to extend the use of automation in primary care, but this will require careful implementation and ongoing evaluation.},
	language = {en},
	number = {6},
	urldate = {2020-06-16},
	journal = {BMJ Open},
	author = {Willis, Matthew and Duckworth, Paul and Coulter, Angela and Meyer, Eric T. and Osborne, Michael},
	month = jun,
	year = {2020},
	keywords = {automation, office, health policy, machine learning, organisation of health services, primary care},
	pages = {e032412},
	file = {6037/Willis et al. - 2020 - Qualitative and quantitative approach to assess of.pdf}
}
